하이퍼파라미터란?
- 정의  
    모델이 학습하는 전반적인 방식을 결정해 주는 값을 뜻해요.
    - 모델 내부에서 자동으로 학습되는 값(가중치·편향 등)과 달리,  
        하이퍼파라미터는 사전에 사람이 직접 설정해야 합니다.
- 예시
    - 학생에게 “하루에 2시간 공부하라”라고 미리 지시하는 것과 비슷해요.
    - 머신러닝에서는 대표적으로 다음과 같은 것들이 있어요:
        - 학습률(learning rate): 한 번에 얼마나 크게 움직여서 학습할지
        - 트리 개수(n_estimators): 랜덤포레스트 등에 사용할 결정 트리 수
        - 이웃 수(K값): K-최근접 이웃(KNN)에서 살펴볼 이웃 샘플 개수
        - 배치 크기(batch size): 딥러닝에서 한 번에 처리할 샘플 수

왜 튜닝이 필요할까?
적절한 하이퍼파라미터 설정을 통해 얻을 수 있는 장점들입니다:
- ✅ 모델 성능 향상
    - 올바른 값을 고르면 예측 정확도가 높아집니다.
- ✅ 과적합(overfitting) 완화
    - 너무 복잡하게 학습되는 것을 막아, 실제 데이터에서도 잘 작동하게 돼요.
- ✅ 학습 효율 개선
    - 적은 시간과 자원으로 더 빠르게 학습할 수 있어요.
- ✅ 데이터 잠재력 최대화
    - 데이터의 중요한 패턴을 놓치지 않고 잘 학습하도록 돕습니다.

---
 어떻게 하이퍼파라미터를 튜닝하나요?
`1.` 그리드 탐색 (Grid Search)
- 사람이 정한 모든 하이퍼파라미터 값 조합을 전부 실험해 봅니다.
- 예:
    - 학습률 = `[0.01, 0.1, 0.2]`
    - 트리 개수 = `[100, 200]`  
        → 총 3×2 = 6가지 조합을 모두 시험
    
`2.` 랜덤 탐색 (Random Search)
- 가능한 조합 중에서 임의로 선택한 일부만 실험합니다.
- 그리드 탐색보다 속도가 빠르면서, 충분히 좋은 값을 찾을 확률이 높아요.
    
---
튜닝한 파라미터는 어떻게 평가하나요?
- 교차 검증(Cross Validation)을 활용합니다.
	- 각 하이퍼파라미터 조합마다 K-Fold 방식 등으로 모델을 평가해 보고,
	- 평균 성능이 가장 높은 조합을 최종 선택합니다.
    
---
예시 비유
학생이 시험 준비할 때:
- 하루 공부 시간
- 과목 순서
- 문제집 반복 횟수 
    등을 다양하게 바꿔가며  
    가장 성적이 잘 나오는 공부법을 찾는 과정이  
    하이퍼파라미터 튜닝이라고 보면 돼요.

```python
# === 그리드 탐색(Grid Search) 예제 ===
from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.ensemble import RandomForestClassifier

# 1) 데이터 준비
data = load_breast_cancer()
X, y = data.data, data.target

# 2) 학습/테스트 분할
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# 3) 모델 초기화
rf = RandomForestClassifier(random_state=42)

# 4) 하이퍼파라미터 후보 그리드 설정
param_grid = {
    'n_estimators': [10, 50, 100, 200],
    'max_depth': [None, 10, 20, 30],
    'min_samples_split': [2, 5, 10]
}

# 5) GridSearchCV 객체 생성
# cv=5 → 5-Fold 교차검증으로 각 조합을 평가
grid_search = GridSearchCV(
    estimator=rf,
    param_grid=param_grid,
    cv=5,
    n_jobs=-1,   # 가능한 모든 CPU 코어 사용
    verbose=1    # 진행 상황 출력
)

# 6) 튜닝 실행
grid_search.fit(X_train, y_train)

# 7) 최적 파라미터와 점수 확인
print("Best parameters:", grid_search.best_params_)
print("Best CV score:", grid_search.best_score_)
```

```python
# === 랜덤 탐색(Random Search) 예제 ===
from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split, RandomizedSearchCV
from sklearn.ensemble import RandomForestClassifier
from scipy.stats import randint

# 1) 데이터 준비
data = load_breast_cancer()
X, y = data.data, data.target

# 2) 학습/테스트 분할
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# 3) 모델 초기화
rf = RandomForestClassifier(random_state=42)

# 4) 하이퍼파라미터 분포 설정
param_dist = {
    'n_estimators': randint(10, 200), # 10~199 중 랜덤 선택
    'max_depth': [None, 10, 20, 30],   # 리스트에서 랜덤 선택
    'min_samples_split': randint(2, 11)   # 2~10 중 랜덤 선택
}

# 5) RandomizedSearchCV 객체 생성
random_search = RandomizedSearchCV(
    estimator=rf,
    param_distributions=param_dist,
    n_iter=100, # 시험할 조합 수
    cv=5,   # 5-Fold 교차검증
    n_jobs=-1,
    verbose=1,
    random_state=42
)

# 6) 튜닝 실행
random_search.fit(X_train, y_train)

# 7) 최적 파라미터와 점수 확인
print("Best parameters:", random_search.best_params_)
print("Best CV score:", random_search.best_score_)
```

