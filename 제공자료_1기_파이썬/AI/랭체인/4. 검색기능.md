ì¢…ë¥˜ ì˜ˆì‹œ:
- í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ í¬í„¸: í‚¤ì›Œë“œ(BM25) + ë²¡í„° ìœ ì‚¬ë„ ê²°í•©í•œ ì •í™• ê²€ìƒ‰   
- ë©€í‹°ë¬¸ì„œ ìš”ì•½ ì§ˆì˜: ìˆ˜ì‹­ ë¬¸ì„œì—ì„œ ì°¾ì•„ ëª¨ì•„ í•œ ë²ˆì— ë‹µë³€  
- ì‹¤ì‹œê°„ í¬ë¡¤ë§â†’ì¸ë±ì‹± íŒŒì´í”„ë¼ì¸: ì£¼ê¸° ìˆ˜ì§‘â†’ì²­í¬â†’ì„ë² ë”©â†’Chroma/PGVector ë°˜ì˜
---
##### ë©€í‹°ë¬¸ì„œ ìš”ì•½ ì§ˆì˜(ìˆ˜ì‹­ ë¬¸ì„œë¥¼ ì°¾ì•„ ëª¨ì•„ í•œ ë²ˆì— ë‹µë³€)
ë‚´ê°€ ëª¨ì•„ ë‘” ë¬¸ì„œë¥¼ ë¨¼ì € ë²¡í„°ë¡œ ì¸ë±ì‹±í•´ ë‘ê³ , í™”ë©´ì—ì„œ ì§ˆë¬¸ì„ ì¹˜ë©´ ê·¸ ì¸ë±ìŠ¤ ê¸°ë°˜ìœ¼ë¡œ ê²€ìƒ‰â†’ìš”ì•½í•´ì„œ ë‹µì„ ë³´ì—¬ì£¼ëŠ” êµ¬ì¡°

`0)` ìƒˆ í”„ë¡œì íŠ¸ & ì„¤ì¹˜
```bash
mkdir multi-doc-qa && cd multi-doc-qa

# ê°€ìƒí™˜ê²½(ì„ íƒ)
python -m venv .venv && source .venv/bin/activate   # (Windows: .venv\Scripts\activate)

# í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜
pip install langchain==0.1.10 langchain-openai langchain-chroma chromadb pypdf python-dotenv fastapi uvicorn
```

`.env`
```env
OPENAI_API_KEY=sk-...              # OpenAI í‚¤
OPENAI_MODEL=gpt-3.5-turbo-0125    # ê¸°ë³¸ LLM (ì›í•˜ë©´ gpt-4o-mini)
EMBED_MODEL=text-embedding-3-small # ì„ë² ë”© ëª¨ë¸(ê°€ì„±ë¹„)
CHROMA_DIR=./chroma                # ë²¡í„°DB ì˜êµ¬í™” ê²½ë¡œ
RAG_COLLECTION=kb                  # ì»¬ë ‰ì…˜ëª…
```

`1)` ë””ë ‰í† ë¦¬ êµ¬ì¡°
```bash
multi-doc-qa/
â”œâ”€ app/
â”‚  â”œâ”€ main.py
â”‚  â”œâ”€ api/
â”‚  â”‚   â””â”€ search_routes.py
â”‚  â””â”€ services/
â”‚      â”œâ”€ retriever.py
â”‚      â””â”€ summarize.py
â”œâ”€ scripts/
â”‚  â””â”€ index_docs.py
â”œâ”€ documents/               # â† ì—¬ê¸°ì— txt/pdf ë¬¸ì„œë“¤ ë„£ê¸°
â”œâ”€ web/
â”‚  â””â”€ index.html            # ì •ì  í”„ë¡ íŠ¸
â”œâ”€ chroma/                  # (ìë™ìƒì„±) Chroma ì˜êµ¬ ì €ì¥ì†Œ
â””â”€ .env
```
`app/`, `app/api/`, `app/services/`ì— `__init__.py`(ë¹ˆ íŒŒì¼)ë¥¼ ë§Œë“¤ì–´ë‘ë©´ importê°€ ì•ˆì •ì ì…ë‹ˆë‹¤.

`2)` ë¬¸ì„œ ì¸ë±ì‹±(ì˜¤í”„ë¼ì¸) â€” `scripts/index_docs.py`
- `documents/` í´ë”ì˜ TXT/PDFë¥¼ ì½ì–´ ì²­í¬ë¡œ ìª¼ê°œê³ ,
- OpenAI ì„ë² ë”©ìœ¼ë¡œ ë²¡í„°í™”í•˜ì—¬ Chromaì— ì˜êµ¬ ì €ì¥í•©ë‹ˆë‹¤.
```python
# scripts/index_docs.py
import os, glob, hashlib
from dotenv import load_dotenv
from pypdf import PdfReader
import chromadb
from langchain_openai import OpenAIEmbeddings
from langchain_chroma import Chroma
from langchain.text_splitter import RecursiveCharacterTextSplitter

load_dotenv()
DOCS_DIR   = os.getenv("DOCS_DIR", "documents")
CHROMA_DIR = os.getenv("CHROMA_DIR", "chroma")
COLLECTION = os.getenv("RAG_COLLECTION", "kb")
EMBED_MODEL= os.getenv("EMBED_MODEL", "text-embedding-3-small")

def read_txt_pdf(path: str) -> str:
    if path.lower().endswith(".txt"):
        return open(path, "r", encoding="utf-8", errors="ignore").read()
    if path.lower().endswith(".pdf"):
        reader = PdfReader(path)
        pages = [page.extract_text() or "" for page in reader.pages]
        return "\n".join(pages)
    return ""

def sha1(s: str) -> str:
    return hashlib.sha1(s.encode("utf-8")).hexdigest()

def main():
    os.makedirs(DOCS_DIR, exist_ok=True)
    os.makedirs(CHROMA_DIR, exist_ok=True)

    files = sorted(glob.glob(os.path.join(DOCS_DIR, "*.*")))
    if not files:
        print(f"[warn] {DOCS_DIR}/ ì— ë¬¸ì„œë¥¼ ë„£ê³  ë‹¤ì‹œ ì‹¤í–‰í•˜ì„¸ìš”.")
        return

    splitter = RecursiveCharacterTextSplitter(chunk_size=900, chunk_overlap=150)
    embeddings = OpenAIEmbeddings(model=EMBED_MODEL)

    # Chroma(Client) ì´ˆê¸°í™” ë° ì»¬ë ‰ì…˜ ì¤€ë¹„
    client = chromadb.PersistentClient(path=CHROMA_DIR)
    try:
        col = client.get_collection(COLLECTION)
    except:
        col = client.create_collection(COLLECTION)

    add_ids, add_docs, add_metas = [], [], []

    for f in files:
        raw = read_txt_pdf(f)
        if not raw.strip():
            print(f"[skip empty] {os.path.basename(f)}")
            continue

        chunks = splitter.split_text(raw)
        for i, ck in enumerate(chunks):
            # ê°™ì€ íŒŒì¼ì´ ì¬ì¸ë±ì‹±ë˜ì–´ë„ ì¤‘ë³µ ì¶”ê°€ë˜ì§€ ì•Šë„ë¡ ID í•´ì‹œ
            _id = sha1(f"{os.path.basename(f)}::{i}::{ck[:80]}")
            add_ids.append(_id)
            add_docs.append(ck)
            add_metas.append({"source": os.path.basename(f), "chunk": i})

    if not add_ids:
        print("ì¶”ê°€í•  ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    # ì´ë¯¸ ë“¤ì–´ê°„ IDëŠ” ì œì™¸ (upsert ëŠë‚Œ)
    existing = set(col.get(ids=add_ids).get("ids", []))
    todo = [(i,d,m) for i,d,m in zip(add_ids, add_docs, add_metas) if i not in existing]
    if not todo:
        print("Nothing new to add.")
        return

    ids, docs, metas = zip(*todo)
    print(f"Embedding {len(ids)} chunks...")
    vecs = embeddings.embed_documents(list(docs))  # ë°°ì¹˜ ì„ë² ë”©

    print("Upserting into Chroma...")
    col.add(ids=list(ids), documents=list(docs), embeddings=list(vecs), metadatas=list(metas))
    print(f"Done. Indexed {len(ids)} chunks into '{COLLECTION}' at {CHROMA_DIR}")

if __name__ == "__main__":
    main()
```
ì¸ë±ì‹±(ë²¡í„°í™”) ì‹¤í–‰
```bash
python scripts/index_docs.py
```
- `documents/` ì•ˆì˜ íŒŒì¼ë“¤ì„ ì²­í¬ â†’ ì„ë² ë”© â†’ Chroma(`chroma/`)ì— ì €ì¥í•©ë‹ˆë‹¤.
- ì™„ë£Œ í›„ â€œIndexed N chunks â€¦â€ ë©”ì‹œì§€ê°€ ëœ¹ë‹ˆë‹¤.

`3)` ê²€ìƒ‰+ìš”ì•½ ì„œë¹„ìŠ¤ â€” `app/services/retriever.py`
- Chromaë¥¼ ì˜êµ¬ ì €ì¥ì†Œì—ì„œ ë¡œë“œí•˜ê³ ,
- ë¦¬íŠ¸ë¦¬ë²„ í•¸ë“¤ì„ ì œê³µí•©ë‹ˆë‹¤.
```python
# app/services/retriever.py
import os
from dotenv import load_dotenv
from langchain_openai import OpenAIEmbeddings
from langchain_chroma import Chroma

load_dotenv()
CHROMA_DIR = os.getenv("CHROMA_DIR", "chroma")
COLLECTION = os.getenv("RAG_COLLECTION", "kb")
EMBED_MODEL= os.getenv("EMBED_MODEL", "text-embedding-3-small")

_embeddings = OpenAIEmbeddings(model=EMBED_MODEL)

# ì´ë¯¸ ì¸ë±ì‹±ëœ ì»¬ë ‰ì…˜ ë¡œë“œ
_vectordb = Chroma(
    collection_name=COLLECTION,
    embedding_function=_embeddings,
    persist_directory=CHROMA_DIR,
)

def get_retriever(k: int = 8):
    return _vectordb.as_retriever(search_kwargs={"k": k})
```

`4)` ë©€í‹°ë¬¸ì„œ ìš”ì•½ ì²´ì¸ â€” `app/services/summarize.py`
- ë¦¬íŠ¸ë¦¬ë²„ë¡œ **ì—¬ëŸ¬ ì²­í¬**ë¥¼ ê°€ì ¸ì˜¨ ë’¤,
- Stuff ì²´ì¸(ë¬¸ì„œ í•œ ë²ˆì—) ë˜ëŠ” Map-Reduce ì²´ì¸(ë¬¸ì„œ ë§ì„ ë•Œ)ì„ ì‚¬ìš©í•´  
    ì§ˆë¬¸ì— ëŒ€í•œ ìµœì¢… ë‹µë³€ê³¼ ì¶œì²˜ë¥¼ ë§Œë“­ë‹ˆë‹¤.
```python
# app/services/summarize.py
import os
from typing import Dict, Any, List
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain_core.documents import Document
from langchain_core.prompts import ChatPromptTemplate
from langchain.chains.combine_documents import (
    create_stuff_documents_chain,
    create_map_reduce_documents_chain,
)
from .retriever import get_retriever

load_dotenv()
MODEL = os.getenv("OPENAI_MODEL", "gpt-3.5-turbo-0125")

# --- ê³µí†µ í”„ë¡¬í”„íŠ¸ ---
# ì»¨í…ìŠ¤íŠ¸ ë°– ì¶”ë¡ ì„ ê¸ˆì§€í•˜ê³ , ì¶œì²˜(íŒŒì¼ëª…)ë¥¼ ë‹µë³€ í•˜ë‹¨ì— ë‚˜ì—´í•˜ë„ë¡ ìœ ë„
BASE_INSTRUCTIONS = """\
ë‹¤ìŒ ì‚¬ìš©ì ì§ˆë¬¸ì— ëŒ€í•´, ì œê³µëœ ë¬¸ì„œ ì»¨í…ìŠ¤íŠ¸ë§Œ ê·¼ê±°ë¡œ í•œêµ­ì–´ë¡œ ë‹µí•˜ì„¸ìš”.
ì»¨í…ìŠ¤íŠ¸ì— ì—†ê±°ë‚˜ ë¶ˆí™•ì‹¤í•˜ë©´ "ëª¨ë¥´ê² ìŠµë‹ˆë‹¤"ë¼ê³  ë‹µí•˜ì„¸ìš”.
ë‹µë³€ ë§ˆì§€ë§‰ì— ì°¸ê³ í•œ ì¶œì²˜(íŒŒì¼ëª…)ë¥¼ bulletë¡œ ë‚˜ì—´í•˜ì„¸ìš”.
"""

STUFF_PROMPT = ChatPromptTemplate.from_messages([
    ("system", BASE_INSTRUCTIONS + "\n\n[ì»¨í…ìŠ¤íŠ¸ ë¬¸ì„œ]\n{context}"),
    ("human", "[ì§ˆë¬¸]\n{question}")
])

MAP_PROMPT = ChatPromptTemplate.from_messages([
    ("system", "ì•„ë˜ ë¬¸ì„œ ì²­í¬ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ëŒ€í•œ í•µì‹¬ ë‹µë³€ í¬ì¸íŠ¸ë§Œ bulletë¡œ ì •ë¦¬í•˜ì„¸ìš”.\në¬¸ì„œê°€ ì§ˆë¬¸ê³¼ ë¬´ê´€í•˜ë©´ 'ë¬´ê´€'ì´ë¼ê³ ë§Œ ì ìœ¼ì„¸ìš”."),
    ("human", "ë¬¸ì„œ ì²­í¬:\n{context}\n\nì§ˆë¬¸: {question}")
])

REDUCE_PROMPT = ChatPromptTemplate.from_messages([
    ("system", BASE_INSTRUCTIONS + "\nì•„ë˜ëŠ” ì—¬ëŸ¬ ë¬¸ì„œ ì²­í¬ë¡œë¶€í„° ë½‘ì€ í•µì‹¬ í¬ì¸íŠ¸ ëª©ë¡ì…ë‹ˆë‹¤. ì¤‘ë³µ/ëª¨ìˆœì„ ì •ë¦¬í•´ ìµœì¢… ë‹µì„ ì“°ì„¸ìš”."),
    ("human", "í•µì‹¬ í¬ì¸íŠ¸ë“¤:\n{context}\n\nì§ˆë¬¸: {question}")
])

_llm = ChatOpenAI(model=MODEL, temperature=0.2)

def _collect_sources(docs: List[Document]) -> List[str]:
    # ì¤‘ë³µ ì œê±°ëœ íŒŒì¼ëª… ë¦¬ìŠ¤íŠ¸
    seen, out = set(), []
    for d in docs:
        src = (d.metadata or {}).get("source")
        if src and src not in seen:
            seen.add(src)
            out.append(src)
    return out

def multi_doc_answer(question: str, k: int = 8) -> Dict[str, Any]:
    retriever = get_retriever(k=k)
    docs: List[Document] = retriever.get_relevant_documents(question)

    if not docs:
        return {"answer": "ëª¨ë¥´ê² ìŠµë‹ˆë‹¤. ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.", "sources": [], "snippets": []}

    # ë¬¸ì„œ ì–‘ì— ë”°ë¼ Stuff(ì‘ìŒ) vs Map-Reduce(í¼) ì„ íƒ
    total_chars = sum(len(d.page_content) for d in docs)
    if total_chars <= 8000:  # ëŒ€ëµì  ê¸°ì¤€
        chain = create_stuff_documents_chain(_llm, STUFF_PROMPT)
        answer = chain.invoke({"question": question, "context": docs})
    else:
        map_chain = create_stuff_documents_chain(_llm, MAP_PROMPT)
        reduce_chain = create_stuff_documents_chain(_llm, REDUCE_PROMPT)
        chain = create_map_reduce_documents_chain(
            llm=_llm,
            map_chain=map_chain,
            reduce_chain=reduce_chain,
            token_max=8000,  # í•„ìš” ì‹œ ì¡°ì •
        )
        answer = chain.invoke({"question": question, "context": docs})

    sources = _collect_sources(docs)
    snippets = [{
        "source": (d.metadata or {}).get("source"),
        "chunk": (d.metadata or {}).get("chunk"),
        "text": d.page_content[:220] + ("â€¦" if len(d.page_content) > 220 else "")
    } for d in docs]

    return {"answer": answer, "sources": sources, "snippets": snippets}
```

`5)` API ë¼ìš°í„° â€” `app/api/search_routes.py`
```python
# app/api/search_routes.py
from fastapi import APIRouter, HTTPException
from pydantic import BaseModel, Field
from app.services.summarize import multi_doc_answer

router = APIRouter(prefix="/search", tags=["search"])

class QueryReq(BaseModel):
    query: str = Field(..., examples=["í™˜ë¶ˆ/ë°˜í’ˆ ì •ì±… ìš”ì•½í•´ì¤˜"])
    k: int = 8

@router.post("/query")
def query(req: QueryReq):
    q = (req.query or "").strip()
    if not q:
        raise HTTPException(400, "query is empty")
    result = multi_doc_answer(q, k=req.k)
    return result
```

`6)` FastAPI ì•± â€” `app/main.py`
```python
# app/main.py
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
from fastapi.responses import RedirectResponse
from app.api.search_routes import router as search_router

app = FastAPI(title="Multi-Doc QA", version="1.0.0")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"], allow_credentials=True,
    allow_methods=["*"], allow_headers=["*"],
)

# API ë¼ìš°í„°
app.include_router(search_router)

# ì •ì  í”„ë¡ íŠ¸ ì„œë¹™
app.mount("/web", StaticFiles(directory="web", html=True), name="web")

@app.get("/")
def root():
    return RedirectResponse(url="/web/")
```

`7)` ì •ì  í”„ë¡ íŠ¸ â€” `web/index.html`
- ê²€ìƒ‰ì°½ì— ì§ˆë¬¸ì„ ì…ë ¥í•˜ë©´ `/search/query`ë¡œ POST
- ë‹µë³€ê³¼ í•¨ê»˜ ì¶œì²˜ ë° ìŠ¤ë‹ˆí«(ê°€ì ¸ì˜¨ ë¬¸ì„œ ì¡°ê°) í‘œì‹œ
```html
<!doctype html>
<html lang="ko">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width,initial-scale=1"/>
  <title>ë©€í‹°ë¬¸ì„œ ìš”ì•½ ì§ˆì˜</title>
  <script src="https://cdn.tailwindcss.com"></script>
</head>
<body class="bg-slate-50 text-slate-900">
  <div class="max-w-4xl mx-auto p-6">
    <h1 class="text-2xl font-bold mb-2">ë©€í‹°ë¬¸ì„œ ìš”ì•½ ì§ˆì˜ (LangChain)</h1>
    <p class="text-sm text-slate-600 mb-6">ì—¬ëŸ¬ ë¬¸ì„œì—ì„œ ì°¾ì•„ ëª¨ì•„ í•œ ë²ˆì— ë‹µë³€í•©ë‹ˆë‹¤.</p>

    <section class="bg-white rounded-2xl shadow p-4 mb-4">
      <form id="qform" class="flex gap-2 items-center">
        <input id="q" class="flex-1 border rounded-xl px-4 py-3 outline-none focus:ring w-full"
               placeholder="ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: ë°˜í’ˆ/í™˜ë¶ˆ ì •ì±… í•µì‹¬ ìš”ì•½)" />
        <input id="k" type="number" min="3" max="20" value="8"
               class="w-24 border rounded-xl px-3 py-3 text-sm" title="Top-k"/>
        <button id="go" class="px-5 py-3 rounded-xl bg-blue-600 text-white hover:bg-blue-700">
          ì§ˆì˜
        </button>
      </form>
    </section>

    <section id="answer" class="bg-white rounded-2xl shadow p-5 mb-4 hidden">
      <h2 class="text-lg font-semibold mb-2">ë‹µë³€</h2>
      <div id="answerText" class="prose max-w-none whitespace-pre-wrap"></div>
      <div id="sources" class="mt-4"></div>
    </section>

    <section id="snippets" class="bg-white rounded-2xl shadow p-5 hidden">
      <div class="flex items-center justify-between mb-2">
        <h2 class="text-lg font-semibold">ì°¸ê³  ìŠ¤ë‹ˆí«</h2>
        <button id="toggleSnip" class="text-sm text-blue-600 hover:underline">í¼ì¹˜ê¸°/ì ‘ê¸°</button>
      </div>
      <div id="snipList" class="space-y-3"></div>
    </section>
  </div>

  <script>
    const form = document.getElementById('qform');
    const input = document.getElementById('q');
    const k = document.getElementById('k');
    const answerBox = document.getElementById('answer');
    const answerText = document.getElementById('answerText');
    const sourcesDiv = document.getElementById('sources');
    const snippetsBox = document.getElementById('snippets');
    const snipList = document.getElementById('snipList');
    const toggleSnip = document.getElementById('toggleSnip');

    let snipOpen = true;
    toggleSnip?.addEventListener('click', () => {
      snipOpen = !snipOpen;
      snipList.style.display = snipOpen ? 'block' : 'none';
    });

    form.addEventListener('submit', async (e) => {
      e.preventDefault();
      const q = input.value.trim();
      if (!q) return;
      setBusy(true);
      showLoading("ì§ˆì˜ ì¤‘â€¦");

      try {
        const res = await fetch('/search/query', {
          method: 'POST',
          headers: {'Content-Type':'application/json'},
          body: JSON.stringify({ query: q, k: Number(k.value || 8) })
        });
        if (!res.ok) {
          const t = await res.text();
          showError(`ì˜¤ë¥˜(${res.status}): ${t}`);
          return;
        }
        const data = await res.json();
        renderResult(data);
      } catch (err) {
        showError('ìš”ì²­ ì‹¤íŒ¨: ' + err);
      } finally {
        setBusy(false);
      }
    });

    function renderResult(data) {
      answerBox.classList.remove('hidden');
      answerText.textContent = data?.answer || '(ë¹ˆ ì‘ë‹µ)';
      sourcesDiv.innerHTML = "";
      if (Array.isArray(data?.sources) && data.sources.length) {
        const ul = document.createElement('ul');
        ul.className = 'list-disc pl-6 text-sm text-slate-700';
        data.sources.forEach(s => {
          const li = document.createElement('li');
          li.textContent = s;
          ul.appendChild(li);
        });
        sourcesDiv.innerHTML = `<h3 class="font-medium mb-1">ì°¸ê³  ì¶œì²˜</h3>`;
        sourcesDiv.appendChild(ul);
      }

      if (Array.isArray(data?.snippets) && data.snippets.length) {
        snippetsBox.classList.remove('hidden');
        snipList.innerHTML = "";
        data.snippets.forEach(sn => {
          const div = document.createElement('div');
          div.className = 'border rounded-xl p-3';
          div.innerHTML = `
            <div class="text-sm text-slate-500 mb-1">ğŸ“„ ${escapeHtml(sn.source)} (chunk ${sn.chunk})</div>
            <div class="text-sm whitespace-pre-wrap">${escapeHtml(sn.text)}</div>
          `;
          snipList.appendChild(div);
        });
      } else {
        snippetsBox.classList.add('hidden');
      }
    }

    function showLoading(msg) {
      answerBox.classList.remove('hidden');
      answerText.textContent = msg;
      sourcesDiv.innerHTML = "";
      snippetsBox.classList.add('hidden');
    }

    function showError(msg) {
      answerBox.classList.remove('hidden');
      answerText.textContent = msg;
      sourcesDiv.innerHTML = "";
      snippetsBox.classList.add('hidden');
    }

    function setBusy(b) {
      document.getElementById('go').disabled = b;
      input.disabled = b;
      k.disabled = b;
    }

    function escapeHtml(s) {
      return String(s).replaceAll('&','&amp;').replaceAll('<','&lt;').replaceAll('>','&gt;');
    }
  </script>
</body>
</html>
```

`8)` ì‹¤í–‰ & í…ŒìŠ¤íŠ¸
ë¬¸ì„œ ë„£ê¸°  
`documents/` í´ë”ì— TXT/PDF ì—¬ëŸ¬ ê°œ ë³µì‚¬

ì¸ë±ì‹±
```bash
python scripts/index_docs.py
```

ì„œë²„ ì‹¤í–‰
```bash
uvicorn app.main:app --reload --port 8000
```

ì„¤ê³„ ìš”ì 
- ì¸ë±ì‹±ì€ ì˜¤í”„ë¼ì¸: ë¬¸ì„œ ë³€ê²½ ì‹œì—ë§Œ ì‹¤í–‰ â†’ ë¹„ìš©/ì§€ì—° ì ˆê°
- Chroma ì˜êµ¬í™”: `CHROMA_DIR`ë¡œ ì¬ì‹œì‘ ì‹œ ì¬ì¸ë±ì‹± ë¶ˆí•„ìš”
- ë¦¬íŠ¸ë¦¬ë²„ k ì¡°ì ˆ: ë„ˆë¬´ í¬ë©´ ì¡ìŒâ†‘, ë„ˆë¬´ ì‘ìœ¼ë©´ ëˆ„ë½â†‘ (8~12 ê¶Œì¥)
- ìŠ¤í… ì„ íƒ: ë¬¸ì„œ ì´ ê¸¸ì´ê°€ ì‘ìœ¼ë©´ Stuff, í¬ë©´ Map-Reduceë¡œ ìë™ ì„ íƒ
- ì¶œì²˜Â·ìŠ¤ë‹ˆí« ì œê³µ: íˆ¬ëª…ì„±/ê²€ì¦ ê°€ëŠ¥ì„± í–¥ìƒ
- í”„ë¡ íŠ¸ ì •ì  ì„œë¹™: ê°™ì€ ì„œë²„ì—ì„œ `/web/`ë¡œ UI ì œê³µ, CORS ìµœì†Œí™”

