
fast api에서 설치해야 하는 패키지
```bash
pip install scikit-learn pandas konlpy joblib fastapi uvicorn jinja2 python-multipart seaborn matplotlib
```

디렉토리 구조
```
sectiment_api/  # 프로젝트 루트
├── venv/ # 가상환경 (파이썬 패키지들)
├── korean_sentiment_dataset_expanded.csv  # 학습용 데이터셋
├── sentiment_model.pkl  # 학습된 감정분석 모델 (pickle)
├── train_sentiment_model.py # 모델 학습/재학습 스크립트
├── tokenizer.py # korean_tokenizer 정의 (형태소 분석)
├── main.py # FastAPI 서버 (예측 엔드포인트, 스타 계산 등)
├── confusion_matrix.png # 학습 평가용 시각화 (혼동 행렬)
├── templates/   # Jinja2 HTML 템플릿
│   ├── base.html # 공통 레이아웃 / 스타일
│   └── index.html # 입력 폼 + 예측 결과 (별점 포함)
└── __pycache__/ # 파이썬 컴파일 캐시
```

requirements.txt
```txt
fastapi
uvicorn[standard]
scikit-learn
pandas
konlpy
jinja2
python-multipart
joblib
matplotlib
seaborn
```
---
웹 서비스 구성 흐름
```
[1] 학습 단계 (오프라인, 수동 실행)
     └── train_sentiment_model.py
         └── 모델 학습 및 평가
         └── => sentiment_model.pkl 저장

[2] 서비스 단계 (FastAPI 서버 실행)
     └── main.py
         └── 서버 시작 시 모델 로딩
         └── 사용자 입력 받음
         └── 예측 결과 반환 (HTML or JSON)
```
즉 AI 모델은 main.py입장에서 보면 이미 한번 훈련된 결과를 읽어와서 사용하는 함수 객체처럼 동작하는 존재입니다.

작동 방식 흐름
```
[학습] train_sentiment_model.py
   ↓
  sentiment_model.pkl 생성 (= 모델의 함수적 행동을 파일로 저장한 것)
   ↓
[서버] main.py
   └─ FastAPI 서버 시작 시 모델 1회 로딩 (@app.on_event("startup"))
        └─ model = pickle.load(...)
   └─ 이후 요청마다 model.predict(...) 호출
```
- `main.py`는 서버 실행 중 딱 한 번만 모델을 메모리에 로드해두고,
- 이후 API 요청이 들어올 때마다 `.predict()` 메서드를 반복해서 호출할 뿐입니다.
- 자연어 처리, 컴퓨터 비전, 음성 인식 등 대부분의 AI 모델은 이와 같은 기본적인 흐름을 따릅니다.
- 모델을 학습(training)한 뒤, 추론(inference) 단계에서 API나 앱에 붙이는 방식입니다.

---
한국어 텍스트를 토큰(단어 단위)으로 분리해주는 함수 `korean_tokenizer()`를 정의한 모듈입니다. `tokenizer.py` 안의 `korean_tokenizer()` 함수는 재사용 가능한 범용 한국어 텍스트 토크나이저입니다.

tokenizer.py 
```python
try:
    from konlpy.tag import Okt
    okt = Okt()
    def korean_tokenizer(text):
        return okt.morphs(text, stem=True)
except ImportError:
    def korean_tokenizer(text):
        return text.split()
```

train_sentiment_model.py
```python
import pickle
import re # 정규 표현식(regular expression) 모듈

import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns
from sklearn.calibration import CalibratedClassifierCV
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline
from tokenizer import korean_tokenizer  # 반드시 같은 디렉터리에 tokenizer.py 존재


# --- 전처리 함수 ---
def normalize_text(text: str) -> str:
    # 반복 글자 줄이기 (예: 너무너무너무 -> 너무너무)
    text = re.sub(r'(\w)\1{2,}', r'\1\1', text)
    # 여러 공백 정리
    text = re.sub(r'\s+', ' ', text).strip()
    return text

# --- 데이터 로드 ---
# CSV 파일로부터 데이터프레임을 불러옵니다 (감정 분석용 확장 데이터셋)
df = pd.read_csv("korean_sentiment_dataset_expanded.csv")

# text 또는 label 컬럼에 결측값(NaN)이 있는 행을 제거합니다
df = df.dropna(subset=["text", "label"])

# label 값을 정수형(int)으로 변환합니다 (예: 0 = 부정, 1 = 긍정)
df["label"] = df["label"].astype(int)

# text 데이터를 문자열(str)로 변환한 후, 
# normalize_text 함수를 통해 전처리합니다
# (예: 중복 글자 제거, 공백 정리 등)
df["text"] = df["text"].astype(str).apply(normalize_text)

# --- train/test split ---
# 학습 80%, 테스트 20%
X_train, X_test, y_train, y_test = train_test_split(
    df["text"], df["label"], test_size=0.2, random_state=42, stratify=df["label"]
)

# --- 파이프라인 정의 ---
# 머신러닝 파이프라인 구성: 
# 텍스트 벡터화(TF-IDF) → 분류기(Logistic Regression) 순서로 처리
base_pipeline = Pipeline([
	
	# 1단계: 텍스트 데이터를 TF-IDF 벡터로 변환
    ("tfidf", TfidfVectorizer(  
	    tokenizer=korean_tokenizer,# Okt 형태소 토크나이저 사용 
	    ngram_range=(1,2), # 1-그램(단어)과 2-그램(단어쌍)까지 고려
	    min_df=1 # 최소 문서 빈도: 1개 문서 이상에 등장한 단어만 사용
    )),
'''
n-gram 이란?
n-gram은 연속된 n개의 단어를 하나의 토큰처럼 처리하는 방식입니다.
문장: "이 영화 정말 좋았어요"
ngram_range=(1, 2) 
1-gram (unigram): 단어 하나하나 → ["이", "영화", "정말", "좋았어요"]
2-gram (bigram): 연속된 두 단어 조합 → ["이 영화", "영화 정말", "정말 좋았어요"]
["이", "영화", "정말", "좋았어요",
 "이 영화", "영화 정말", "정말 좋았어요"]
위와 같이 모든 조합을 피처(특징)로 사용하게 됩니다
이유는 "재미"는 중립 단어이고 "재미있다" "재미없다"는 감정이 확실해집니다.
그래서 2-gram을 보면 감정이 확실해지기 때문에 위와 같이 사용합니다.
'''
		
		
	# 2단계: 로지스틱 회귀 모델을 사용한 감정 분류
    ("clf", LogisticRegression(
	    
	    # 학습 최대 반복 횟수 (기본값보다 크게 설정하여 수렴 유도) 
	    max_iter=2000,
	    
	    # 클래스 불균형 보정 (가중치를 자동으로 조정)
	    class_weight="balanced" 
    ))
])

# 확률 보정을 위해 CalibratedClassifierCV wrapping (sigmoid or isotonic)
calibrated = CalibratedClassifierCV(base_pipeline, cv=3, method="sigmoid")

# --- 학습 ---
calibrated.fit(X_train, y_train)

# --- 평가 ---
# 테스트 데이터셋(X_test)에 대해 학습된 모델(calibrated)로 예측 수행
y_pred = calibrated.predict(X_test)

# 예측 결과(y_pred)와 실제 정답(y_test)을 비교해 정확도(Accuracy)를 계산
acc = accuracy_score(y_test, y_pred)

# 정확도 출력
print("Accuracy:", acc)

# digits=4 → 소수점 아래 4자리까지 출력
print("Classification Report:\n", classification_report(y_test, y_pred, digits=4))

'''
- Accuracy(정확도): 전체 샘플 중 정답을 맞춘 비율 
- Precision(정밀도): 양성으로 예측한 것 중 실제로 양성인 비율  
- Recall(재현율): 실제 양성인 것 중 모델이 양성이라고 예측한 비율   
- F1-score: 정밀도와 재현율의 조화 평균 (불균형 데이터일 때 중요)
'''


# 혼동 행렬(confusion matrix)을 시각화하여 이미지(히트맵)로 저장하는 부분
# 실제 레이블(y_test)과 예측 결과(y_pred)를 비교해 혼동 행렬 생성
# labels=[1, 0] → 긍정(1), 부정(0) 순서로 행렬을 출력
cm = confusion_matrix(y_test, y_pred, labels=[1, 0])

# 콘솔에 혼동 행렬 출력
print("Confusion Matrix:\n", cm)
try:
	# 4x3 크기의 새로운 플롯(그림) 생성
    plt.figure(figsize=(4,3))
    
    
    # Seaborn을 이용해 혼동 행렬을 히트맵(heatmap) 형태로 시각화
    # annot=True → 각 셀에 숫자 표기
    # fmt="d" → 정수 형식으로 표기
    # cmap="Blues" → 파란색 계열 컬러맵
    # x/y 축 레이블을 "긍정", "부정"으로 표시
	    sns.heatmap(
	    cm, 
	    annot=True, 
	    fmt="d", 
	    cmap="Blues", 
	    xticklabels=["긍정", "부정"], 
	    yticklabels=["긍정", "부정"]
    )
	
	# x축 레이블
    plt.xlabel("Predicted") # 예측값
    
    # y축 레이블
    plt.ylabel("True") # 실제값
    
    # 그래프 제목 설정
    plt.title("Confusion Matrix")
    
    # 레이아웃을 자동 정리
    plt.tight_layout()
    
    # 시각화 결과를 PNG 파일로 저장
    plt.savefig("confusion_matrix.png")
    
    # 저장 완료 메시지 출력
    print("혼동 행렬을 confusion_matrix.png로 저장했습니다.")
    
# 만약 실행 환경에 시각화 도구(예: GUI 백엔드)가 없으면 오류 발생 → 무시하고 통과    
except Exception:
    pass  # 시각화 환경 없으면 넘어감

# --- 모델 저장 ---
with open("sentiment_model.pkl", "wb") as f:
    pickle.dump(calibrated, f)
print("모델 저장 완료: sentiment_model.pkl")
```

모델 학습 시키기 위한 실행
```bash
python train_sentiment_model.py
```

sectiment_api/main.py
```python
import os
import pickle
import re

from fastapi import FastAPI, Form, Request
from fastapi.responses import HTMLResponse, JSONResponse
from fastapi.templating import Jinja2Templates
from tokenizer import korean_tokenizer  # 피클 모델에서 필요

app = FastAPI()
templates = Jinja2Templates(directory="templates")

model = None  # 전역 모델 변수

# 룰 기반 감정 사전
NEG_WORDS = {"싫어", "별로", "재미없어", "지루해", "실망", "아깝", "아까웠어", "싫었어", "비추"}
POS_WORDS = {"재미있어", "좋았어", "추천", "감동", "완벽", "훌륭", "좋아", "기분좋아", "재밌어"}

# 텍스트 정규화
def normalize_text(text: str) -> str:
    text = re.sub(r'(\w)\1{2,}', r'\1\1', text)  # 반복 글자 줄이기
    text = re.sub(r'\s+', ' ', text).strip()    # 공백 정리
    return text

def rule_override(text: str):
    lowered = text.replace(" ", "").lower()
    if any(w in lowered for w in NEG_WORDS):
        return 0
    if any(w in lowered for w in POS_WORDS):
        return 1
    return None

# 별점 계산
def compute_stars(pred: int, confidence: float) -> int:
    if pred == 1:
        if confidence is None or not (0.0 <= confidence <= 1.0):
            return 3  # 기본 중간값
        return max(1, min(5, round(confidence * 5)))
    return 0  # 부정이면 별 없음

# 서버 시작 시 모델 로드
@app.on_event("startup")
def load_model():
    global model
    if not os.path.exists("sentiment_model.pkl"):
        raise RuntimeError("sentiment_model.pkl이 없습니다. 학습 후 저장해주세요.")
    with open("sentiment_model.pkl", "rb") as f:
        model = pickle.load(f)

# 폼 렌더링
@app.get("/", response_class=HTMLResponse)
def get_form(request: Request):
    return templates.TemplateResponse("index.html", {"request": request})

# 웹 폼 예측 처리
@app.post("/predict", response_class=HTMLResponse)
async def predict(request: Request, text: str = Form(...)):
    original = text or ""
    text = normalize_text(original)

    pred = None
    confidence = 0.0

    rule = rule_override(text)
    if rule is not None:
        pred = rule
        confidence = 0.99
    else:
        if model is None:
            return templates.TemplateResponse("index.html", {
                "request": request,
                "error": "모델이 로드되지 않았습니다.",
                "input_text": original
            })
        try:
            pred = model.predict([text])[0]
            confidence = None
            if hasattr(model, "predict_proba"):
                try:
                    confidence = model.predict_proba([text])[0][pred]
                except Exception:
                    pass
        except Exception as e:
            return templates.TemplateResponse("index.html", {
                "request": request,
                "error": f"예측 중 오류: {e}",
                "input_text": original
            })

    stars = compute_stars(int(pred), confidence)
    confidence_display = confidence if confidence is not None else None

    result = {
        "text": original,
        "prediction": int(pred),
        "label": "positive" if pred == 1 else "negative",
        "confidence": confidence_display,
        "stars": stars,
    }

    return templates.TemplateResponse("index.html", {
        "request": request,
        "result": result,
        "input_text": original
    })

# JSON API 엔드포인트
@app.post("/api/predict")
async def api_predict(payload: dict):
    text = payload.get("text", "")
    if not text:
        return JSONResponse({"error": "text 필드 필요"}, status_code=400)

    normalized = normalize_text(text)

    rule = rule_override(normalized)
    if rule is not None:
        pred = rule
        confidence = 0.99
    else:
        if model is None:
            return JSONResponse({"error": "모델 로드 실패"}, status_code=500)
        try:
            pred = model.predict([normalized])[0]
            confidence = None
            if hasattr(model, "predict_proba"):
                try:
                    confidence = model.predict_proba([normalized])[0][pred]
                except Exception:
                    pass
        except Exception as e:
            return JSONResponse({
                "error": f"예측 실패: {e}",
                "confidence": None,
                "note": "모델 예측 실패"
            }, status_code=500)

    stars = compute_stars(int(pred), confidence)
    confidence_display = confidence if confidence is not None else None

    return {
        "text": text,
        "prediction": int(pred),
        "label": "positive" if pred == 1 else "negative",
        "confidence": confidence_display,
        "stars": stars,
    }
```

코드해석:
```python
import os
import pickle
import re # 정규 표현식(regular expression) 모듈

# # FastAPI 관련 모듈
from fastapi import FastAPI, Form, Request
from fastapi.responses import HTMLResponse, JSONResponse
from fastapi.templating import Jinja2Templates

# 토크나이저 함수 (konlpy.Okt 또는 fallback)
from tokenizer import korean_tokenizer # 있어야 pickle 내부 참조 복원

app = FastAPI()

# HTML 템플릿 디렉토리 설정 (templates/index.html 사용)
templates = Jinja2Templates(directory="templates")

# 전역 모델 변수 (앱 시작 시 모델을 로딩하여 여기에 저장)
model = None # 감정분석 모델 전역변수

# 사전 정의된 감정 단어들 (룰 기반 우선 처리용)
NEG_WORDS = {"싫어", "별로", "재미없어", "지루해", "실망", "아깝", "아까웠어", "싫었어", "비추"}
POS_WORDS = {"재미있어", "좋았어", "추천", "감동", "완벽", "훌륭", "좋아", "기분좋아", "재밌어"}

# 텍스트 전처리 함수: 반복 글자 줄이고, 공백 정리
def normalize_text(text: str) -> str:
	
	# 같은 글자가 3번 이상 반복될 경우, 2번만 남김 (ex: ㅋㅋㅋㅋ → ㅋㅋ)
    text = re.sub(r'(\w)\1{2,}', r'\1\1', text)
	
	# 공백이 여러 개일 경우, 하나로 줄이고 양쪽 공백 제거
    text = re.sub(r'\s+', ' ', text).strip()
    return text

# 룰 기반 감정 처리 함수: 
# 강한 단어가 포함되어 있으면 무조건 해당 감정으로 판단
def rule_override(text: str):
    lowered = text.replace(" ", "").lower()
    
    for w in NEG_WORDS:
        if w in lowered:
            return 0 # 부정
    for w in POS_WORDS:
        if w in lowered:
            return 1 # 긍정
    return None # 룰 적용 불가시 → 모델에게 넘김

# 예측 결과를 기반으로 별점(1~5)을 계산하는 함수
def compute_stars(pred: int, confidence: float) -> int:
    """
    예측 결과(pred)와 confidence 값을 바탕으로 별점(0~5)을 계산합니다.
	
    - 긍정(pred=1): confidence에 따라 1~5점
    - 부정(pred=0): 무조건 0점
    - confidence가 None이거나 이상치면 기본값 사용
    """
	
    if pred == 1:
        if confidence is None or not (0.0 <= confidence <= 1.0):
            # 신뢰도 계산 불가하거나 이상한 값일 경우 → 기본 별점 3점
            return 3
        # 신뢰도 기반으로 1~5점 (0.0~1.0 → 1~5로 변환)
        return max(1, min(5, round(confidence * 5)))
    return 0  # 부정은 무조건 별점 0점

# [1] FastAPI 애플리케이션 시작 시 모델 로드
@app.on_event("startup")
def load_model():
    global model
    if not os.path.exists("sentiment_model.pkl"):
        raise RuntimeError("sentiment_model.pkl이 없습니다. 먼저 학습 스크립트를 실행하세요.")
    with open("sentiment_model.pkl", "rb") as f:
        model = pickle.load(f)

# [2] 루트 페이지 GET 요청 → HTML 폼 페이지 반환
@app.get("/", response_class=HTMLResponse)
def get_form(request: Request):
    return templates.TemplateResponse("index.html", {"request": request})

# [3] 폼에 작성한 텍스트 → 감정 예측 → HTML에 결과 표시
@app.post("/predict", response_class=HTMLResponse)

# Form(...)은 반드시 form으로 전달되어야 함을 의미
async def predict(request: Request, text: str = Form(...)):
    original = text or ""
    text = normalize_text(original)
    # 기본값
    pred = None
    confidence = 0.0

    # 룰기반 감정예측이란, 기계학습(ML 모델)을 사용하지 않고, 
    # 사람이 정의한 규칙(=룰)에 따라 감정을 분류하는 방법입니다.
    # [1단계] 룰 기반 감정 예측
    rule = rule_override(text)
    if rule is not None:
        pred = rule
        confidence = 0.99
    else:

		# 머신러닝 모델 기반 예측
        if model is None:
            return templates.TemplateResponse("index.html", {
                "request": request,
                "error": "모델이 로드되지 않았습니다.",
                "input_text": original
            })
        try:
            pred = model.predict([text])[0]
            if hasattr(model, "predict_proba"):
                try:
                    confidence = model.predict_proba([text])[0][pred] # 확률 추정
                except Exception:
                    confidence = 1.0 # 실패 시 기본값
            else:
                confidence = 1.0
        except Exception as e:
            return templates.TemplateResponse("index.html", {
                "request": request,
                "error": f"예측 중 오류: {e}",
                "input_text": original
            })

	# 별점 계산
    stars = compute_stars(int(pred), confidence)
    confidence_display = f"{confidence:.2f}" if confidence is not None else "신뢰도 계산 불가"
    
    result = {
        "text": original,
        "prediction": int(pred),
        "label": "positive" if pred == 1 else "negative",
	    "confidence": confidence_display,  # 문자열 or 신뢰도
        "stars": stars,
    }
    
    # HTML로 결과 반환
    return templates.TemplateResponse("index.html", {
        "request": request,
        "result": result,
        "input_text": original
    })

# [4] API 전용 JSON 예측 엔드포인트 (POST 방식, JSON body 필요)
# 이 함수는 외부에서 JSON 형태로 텍스트를 받아 감정 분석 결과(긍정/부정, 확률 등)를 JSON으로 반환합니다.
@app.post("/api/predict") # HTTP POST 요청을 /api/predict URL로 받을 때 실행

# 요청의 JSON body는 자동으로 파싱되어 payload 딕셔너리로 들어옴
async def api_predict(payload: dict):

	# JSON에서 text라는 키의 값을 가져옴. 없으면 빈 문자열("") 기본값.
    text = payload.get("text", "")
    if not text:
    
# text가 비어있다면 잘못된 요청으로 판단하고 400 Bad Request 응답 반환
        return JSONResponse({"error": "text 필드 필요"}, status_code=400)
        
    # 전처리: 반복 글자 제거, 공백 정리 등    
    normalized = normalize_text(text)
    
    # 사전에 정의된 강한 신호 단어들로 예외 처리 시도 (룰 기반 분류)
    rule = rule_override(normalized)
    if rule is not None:
	    
        # 룰 기반으로 감정이 명확하게 판별된 경우
        pred = rule # 예측 결과: 1(긍정) 또는 0(부정)
        confidence = 0.99 # 매우 높은 신뢰도로 간주
    else:
	    
        # 룰 기반 판별이 안 되는 경우 → 머신러닝 모델로 예측
        if model is None:
	        
	        # 모델이 아직 로드되지 않은 경우 서버 에러로 응답
            return JSONResponse({"error": "모델 로드 실패"}, status_code=500)
        try:
		        
	        # 모델을 통해 감정 예측 (0 또는 1 반환)
            pred = model.predict([normalized])[0]
	            
            # 예측 확률을 지원하는 모델이라면
            if hasattr(model, "predict_proba"):
                try:
	                
	                # 해당 예측에 대한 확률값
                    confidence = model.predict_proba([normalized])[0][pred]
                except Exception:
	                # 예외 발생 시 확률값은 기본값 1.0 사용
                    confidence = None 
            else:
	            # 확률 예측이 불가능한 모델인 경우도 1.0
                confidence = None
        except Exception as e:
            return JSONResponse({
            "error": f"예측 실패: {e}",
            "confidence": None,
            "note": "모델의 신뢰도(확률값)를 계산할 수 없습니다."
        }, status_code=500)

	# 별점 계산
    confidence_display = f"{confidence:.2f}" if confidence is not None else "신뢰도 계산 불가"

    
    # JSON 응답 반환
    return {
        "text": text,
        "prediction": int(pred),
        "label": "positive" if pred == 1 else "negative",
        "confidence": confidence_display,
        "stars": stars,
    }
```

templates/base.html
```html
<!doctype html>
<html lang="ko">
<head>
  <meta charset="utf-8" />
  <title>{% block title %}한글 감정분석{% endblock %}</title>
  <style>
    body { font-family: Arial, sans-serif; max-width: 700px; margin: 40px auto; line-height:1.4; }
    textarea { width: 100%; height: 120px; }
    .result { margin-top: 20px; padding: 12px; border: 1px solid #444; border-radius: 6px; }
    .positive { color: green; }
    .negative { color: red; }
    .error { color: crimson; }
    .btn { padding: 8px 16px; border: none; background: #2563eb; color: white; border-radius: 4px; cursor: pointer; }
    .stars { font-size: 1.5rem; line-height:1; }
    .star { display: inline-block; }
    .filled { color: gold; }
    .empty { color: #ddd; }
    .label-row { margin: 4px 0; }
  </style>
</head>
<body>
  <h2>한글 감정분석기</h2>
  {% block content %}{% endblock %}
</body>
</html>
```

templates/index.html
```html
{% extends "base.html" %}

{% block title %}감정분석{% endblock %}

{% block content %}
  <form method="post" action="/predict">
    <label for="text">영화후기:</label><br/>
    <textarea name="text" required placeholder="영화에 대한 한줄평을 입력하세요...">{{ input_text | default("") }}</textarea><br/><br/>
    <button class="btn" type="submit">예측</button>
  </form>

 {% if result %}
  <div class="result">
    <p><strong>입력:</strong> {{ result.text }}</p>
    <p><strong>예측:</strong>
      {% if result.prediction == 1 %}
        <span class="positive">긍정</span>
      {% else %}
        <span class="negative">부정</span>
      {% endif %}
    </p>
    <p><strong>확신도:</strong> {{ (result.confidence * 100) | round(2) }}%</p>
    <div>
      <strong>별점:</strong>
      <span class="stars" aria-label="별점">
        {% set filled = result.stars %}
        {% for i in range(1,6) %}
          {% if i <= filled %}
            <span class="star filled">&#9733;</span>
          {% else %}
            <span class="star empty">&#9733;</span>
          {% endif %}
        {% endfor %}
        {% if result.prediction == 0 %}
          <span style="margin-left:8px; color:#888;">(부정적이라 별점 없음)</span>
        {% endif %}
      </span>
    </div>
  </div>
{% endif %}
{% endblock %}
```

브라우저 실행
```bash
uvicorn main:app --reload --host 127.0.0.1 --port 8000
```

![[Pasted image 20250803172144.png]]

---
DRF일경우 디렉토리 구조
```
myproject/
├── ai_model/                    ← 모델 로딩/예측 유틸
│   ├── __init__.py
│   ├── model_utils.py           ← .pkl 모델 불러오기 및 predict 함수
│   ├── sentiment_model.pkl      ← 학습된 모델
│   └── tokenizer.py             ← 토크나이저 (필요 시)
│
├── dataset/                     ← 원본 데이터 및 학습 코드 (옵션)
│   ├── korean_sentiment_dataset.csv
│   ├── train_sentiment_model.py    ← 모델 학습용 스크립트
│   └── confusion_matrix.png        ← 시각화 결과 등
│
├── sentiment/                      ← DRF 앱 (감정 분석 API)
│   ├── __init__.py
│   ├── views.py                    ← 입력 받고 예측 결과 반환
│   ├── urls.py                     ← API 엔드포인트 라우팅
│   └── serializers.py              ← 입력 텍스트 유효성 검사용
│
├── templates/                      ← HTML 템플릿 렌더링 (선택)
│   └── result.html
│
├── myproject/                      ← Django 프로젝트 설정
│   ├── __init__.py
│   ├── settings.py
│   ├── urls.py                     ← sentiment.urls 연결
│   └── wsgi.py
│
├── manage.py
└── requirements.txt
```

| 폴더/파일                      | 역할                                   |
| -------------------------- | ------------------------------------ |
| `ai_model/model_utils.py`  | `.pkl` 모델을 1회만 불러오고, 예측 함수 제공        |
| `sentiment/views.py`       | DRF `APIView` 또는 `@api_view`로 API 작성 |
| `sentiment/urls.py`        | `/predict/` 같은 경로 설정                 |
| `serializers.py`           | 입력 텍스트에 대한 유효성 검증 (Django의 Form 역할)  |
| `templates/result.html`    | 예측 결과를 HTML로 보여줄 때 사용                |
| `train_sentiment_model.py` | 학습 코드, DRF 서버와는 독립적                  |
| `tokenizer.py`             | 전처리 함수 (예: Okt, Mecab 등 포함 가능)       |

---

디렉토리 구조
```
people/    # 프로젝트 루트 (예: 표정 예측 서비스)
├── train_emotion.py # 감정 분류기 학습 스크립트
├── main.py   # FastAPI 서버 (업로드 → 예측 → 템플릿 렌더링)
├── feature_utils.py  # 얼굴 랜드마크로부터 피처를 계산하는 함수들 (ear, mouth_open 등)
├── labeled_expressions.csv  # 이미지 경로 + 라벨 매핑 (학습용)
├── emotion_model.joblib     # 학습된 감정 분류기 저장 파일
├── templates/               # Jinja2 템플릿
│   ├── index.html          # 업로드 폼
│   └── result.html         # 예측 결과 페이지
├── static/                 # 정적 자원
│   └── outputs/            # 예측 후 생성된 이미지들 (annotated)
│       └── <uuid>.png
└── samples/   # 예제/라벨링용 이미지 (train_emotion.py에서 참조)
    ├── angry1.jpg
    ├── angry2.jpg
    ├── smile1.jpg
    ├── smile2.jpg
    ├── normal1.jpg
    └── ...
```

train_emotion.py
```python
import os
from collections import Counter

import cv2
import joblib
import mediapipe as mp
import numpy as np
import pandas as pd

# --- 공통 함수/모델 정의를 가져옴 (feature_vector, face_mesh) ---
# main.py와 같은 디렉터리에 있어야 하고, 그 파일 안에 face_mesh와 feature_vector가 정의되어 있어야 한다.
from main import face_mesh, feature_vector  # 경로가 다르면 상대 경로 조정 필요

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report
from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler

# --- 설정 / 파일 경로 ---
CSV_PATH = "labeled_expressions.csv"       # 라벨된 이미지 CSV
MODEL_OUTPUT = "emotion_model.joblib"       # 저장할 학습된 모델 파일명

# -------------------------------
# 1. 데이터 로드
# -------------------------------
df = pd.read_csv(CSV_PATH)
if df.empty:
    raise RuntimeError("라벨 CSV가 비어있거나 못 읽었습니다.")

# -------------------------------
# 2. 전처리: 이미지에서 얼굴 랜드마크 추출하고 feature vector 생성
# -------------------------------
X = []
y = []
failed = 0

for _, row in df.iterrows():
    img_path = row["image_path"]
    label = row["label"]

    # 이미지 존재 여부 확인
    if not os.path.exists(img_path):
        print(f"[WARN] 이미지 없음: {img_path}, 건너뜀")
        failed += 1
        continue

    img = cv2.imread(img_path)
    if img is None:
        print(f"[WARN] 이미지 로드 실패: {img_path}")
        failed += 1
        continue

    # CV2 처리를 위한 RGB 변환 ( #F90000)
    rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    results = face_mesh.process(rgb)
    if not results.multi_face_landmarks:
        print(f"[WARN] 얼굴 랜드마크 감지 실패: {img_path}")
        failed += 1
        continue

    face_landmarks = results.multi_face_landmarks[0]
    h, w, _ = img.shape

    # feature vector 추출 (main.py에 정의된 함수)
    feat = feature_vector(face_landmarks, w, h)

    # 고정된 순서로 벡터화 (모델 학습/추론 일관성 확보)
    order = ["ear", "mouth_open", "smile_lift", "normalized_mouth_width", "smile_score", "brow_raise", "furrow"]
    X.append([feat[k] for k in order])
    y.append(label)

if len(X) == 0:
    raise RuntimeError("사용할 수 있는 학습 샘플이 하나도 없습니다.")

X = np.array(X, dtype=float)
y = np.array(y)

# 클래스 분포 출력 (분석용)
label_counts = Counter(y)
print("클래스별 샘플 수:", dict(label_counts))

# -------------------------------
# 3. 학습/검증 데이터 분리
# -------------------------------
# stratify 가능 여부 판단: 모든 클래스에 최소 2개 이상 있어야 한다
do_stratify = all(count >= 2 for count in label_counts.values())
use_split = len(y) >= 4  # 너무 적으면 검증 없이 전체 학습

if use_split:
    if do_stratify:
        print("[INFO] stratified split 사용")
        X_train, X_val, y_train, y_val = train_test_split(
            X, y, stratify=y, test_size=0.2, random_state=42
        )
    else:
        print("[INFO] stratify 불가, 일반 split 사용")
        X_train, X_val, y_train, y_val = train_test_split(
            X, y, test_size=0.2, random_state=42, shuffle=True
        )
else:
    print("[WARN] 샘플이 너무 적습니다. 검증 없이 전체 데이터로 학습합니다.")
    X_train, y_train = X, y
    X_val, y_val = None, None

# -------------------------------
# 4. 모델 정의 및 학습
# -------------------------------
# 파이프라인: 정규화 + 로지스틱 회귀 (불균형 대응)
pipeline = Pipeline([
    ("scaler", StandardScaler()),
    ("clf", LogisticRegression(max_iter=2000, class_weight="balanced"))
])

pipeline.fit(X_train, y_train)

# -------------------------------
# 5. 평가 (검증 데이터가 있을 경우)
# -------------------------------
if X_val is not None:
    pred = pipeline.predict(X_val)
    print("평가:\n", classification_report(y_val, pred, digits=4))
else:
    print("[INFO] 검증 데이터 없음, 평가 생략")

# -------------------------------
# 6. 모델 저장
# -------------------------------
joblib.dump(pipeline, MODEL_OUTPUT)
print(f"저장됨: {MODEL_OUTPUT}")
```


`main.py`
```python
import math
import os
import uuid

import cv2
import joblib  # 학습된 scikit-learn 모델 불러오기용
import mediapipe as mp
import numpy as np
from fastapi import FastAPI, File, Request, UploadFile
from fastapi.responses import HTMLResponse
from fastapi.staticfiles import StaticFiles
from fastapi.templating import Jinja2Templates

# ===============================
# 1. 설정 / 초기화
# ===============================
app = FastAPI()
BASE_DIR = os.path.dirname(os.path.abspath(__file__))

# Jinja2 템플릿 경로 설정 (index.html / result.html)
templates = Jinja2Templates(directory=os.path.join(BASE_DIR, "templates"))

# 결과 이미지 저장 위치
OUTPUT_DIR = os.path.join(BASE_DIR, "static", "outputs")
os.makedirs(OUTPUT_DIR, exist_ok=True)

# 정적 파일 (이미지 등) 제공
app.mount("/static", StaticFiles(directory=os.path.join(BASE_DIR, "static")), name="static")

# MediaPipe Face Mesh 초기화 (얼굴 랜드마크 추출)
mp_face_mesh = mp.solutions.face_mesh
face_mesh = mp_face_mesh.FaceMesh(static_image_mode=True, refine_landmarks=True, max_num_faces=1)
mp_drawing = mp.solutions.drawing_utils

# 랜드마크 인덱스 정의 (MediaPipe 기준)
LEFT_EYE_IDX = [33, 133, 160, 159, 158, 157, 173]
RIGHT_EYE_IDX = [362, 263, 387, 386, 385, 384, 398]
NOSE_TIP_IDX = [1]
MOUTH_IDX = [78, 95, 88, 178, 87, 14, 317, 402, 318, 324]

# EAR 계산용 눈 깜박임 관련 인덱스
LEFT_EYE_EAR_IDX = [33, 160, 158, 133, 153, 144]
RIGHT_EYE_EAR_IDX = [362, 387, 385, 263, 373, 380]

# 입 관련 랜드마크
MOUTH_LEFT = 61
MOUTH_RIGHT = 291
MOUTH_TOP = 13
MOUTH_BOTTOM = 14
MOUTH_CORNER_LEFT = 61
MOUTH_CORNER_RIGHT = 291
MOUTH_CENTER_TOP = 13

# 눈썹 관련 (중간 부위)
LEFT_INNER_BROW = 55
RIGHT_INNER_BROW = 285

# 학습된 감정 분류 모델 로드 (있으면 사용, 없으면 룰 기반만)
MODEL_PATH = os.path.join(BASE_DIR, "emotion_model.joblib")
classifier = None
if os.path.exists(MODEL_PATH):
    try:
        classifier = joblib.load(MODEL_PATH)
    except Exception:
        classifier = None  # 로드 실패하면 무시하고 룰 기반만 사용

# ===============================
# 2. 유틸 함수: 기하/피처 계산
# ===============================
def euclidean(a, b):
    """2D 좌표 간 유클리디안 거리 계산"""
    return math.hypot(a[0] - b[0], a[1] - b[1])

def extract_region_info(landmarks, idx_list, image_w, image_h):
    """
    특정 부위(눈, 입 등)의 랜드마크로부터 중심, 바운딩박스, 점 목록을 추출하여 정보를 정리.
    결과는 템플릿 출력용 JSON 형태.
    """
    pts = []
    for idx in idx_list:
        lm = landmarks.landmark[idx]
        pts.append((lm.x * image_w, lm.y * image_h))
    if not pts:
        return None
    xs, ys = zip(*pts)
    centroid = (sum(xs)/len(xs), sum(ys)/len(ys))
    bbox = (min(xs), min(ys), max(xs), max(ys))
    return {
        "centroid": {"x": round(centroid[0],1), "y": round(centroid[1],1)},
        "bbox": {
            "xmin": round(bbox[0],1),
            "ymin": round(bbox[1],1),
            "xmax": round(bbox[2],1),
            "ymax": round(bbox[3],1)
        },
        "points": [{"x": round(p[0],1), "y": round(p[1],1)} for p in pts]
    }

def draw_region(overlay, region, color):
    """추출된 부위 정보를 이미지 위에 바운딩박스/중심/포인트로 시각화"""
    if not region:
        return
    xmin, ymin = int(region["bbox"]["xmin"]), int(region["bbox"]["ymin"])
    xmax, ymax = int(region["bbox"]["xmax"]), int(region["bbox"]["ymax"])
    cv2.rectangle(overlay, (xmin,ymin), (xmax,ymax), color, 2)
    cx, cy = int(region["centroid"]["x"]), int(region["centroid"]["y"])
    cv2.circle(overlay, (cx, cy), 4, color, -1)
    for p in region["points"]:
        cv2.circle(overlay, (int(p["x"]), int(p["y"])), 2, color, -1)

def compute_eye_aspect_ratio(landmarks, idxs, image_w, image_h):
    """눈의 모양을 기반으로 한 EAR 계산 (깜박임/눈 감김 감지에 유용)"""
    pts = []
    for idx in idxs:
        lm = landmarks.landmark[idx]
        pts.append((lm.x * image_w, lm.y * image_h))
    if len(pts) < 6:
        return None
    horiz = euclidean(pts[0], pts[3])
    vert1 = euclidean(pts[1], pts[5])
    vert2 = euclidean(pts[2], pts[4])
    if horiz == 0:
        return 0
    return (vert1 + vert2) / (2.0 * horiz)

def compute_mouth_opening(landmarks, image_w, image_h):
    """입이 얼마나 벌어졌는지 비율로 계산"""
    top = landmarks.landmark[MOUTH_TOP]
    bottom = landmarks.landmark[MOUTH_BOTTOM]
    left = landmarks.landmark[MOUTH_LEFT]
    right = landmarks.landmark[MOUTH_RIGHT]
    vertical = euclidean((top.x*image_w, top.y*image_h), (bottom.x*image_w, bottom.y*image_h))
    horizontal = euclidean((left.x*image_w, left.y*image_h), (right.x*image_w, right.y*image_h))
    if horizontal == 0:
        return 0
    return vertical / horizontal

def feature_vector(face_landmarks, image_w, image_h):
    """
    얼굴 랜드마크를 받아 여러 규칙 기반 피처를 만들고 정규화하여 벡터로 구성.
    감정 추론의 입력이 되는 피처 모음.
    """
    left_ear = compute_eye_aspect_ratio(face_landmarks, LEFT_EYE_EAR_IDX, image_w, image_h)
    right_ear = compute_eye_aspect_ratio(face_landmarks, RIGHT_EYE_EAR_IDX, image_w, image_h)
    ear = None
    if left_ear is not None and right_ear is not None:
        ear = (left_ear + right_ear) / 2.0
    mouth_open = compute_mouth_opening(face_landmarks, image_w, image_h)

    # 얼굴 너비 기준 (눈 사이 거리)
    eye_left = face_landmarks.landmark[33]
    eye_right = face_landmarks.landmark[263]
    face_width = euclidean((eye_left.x*image_w, eye_left.y*image_h), (eye_right.x*image_w, eye_right.y*image_h))

    # 입꼬리와 입 중앙 높이 차이로 웃음 / 입 모양 분석
    corner_left = face_landmarks.landmark[MOUTH_CORNER_LEFT]
    corner_right = face_landmarks.landmark[MOUTH_CORNER_RIGHT]
    center_top = face_landmarks.landmark[MOUTH_CENTER_TOP]
    smile_lift = ((center_top.y - corner_left.y) + (center_top.y - corner_right.y)) / 2.0  # 양수면 입꼬리 올라감
    mouth_width = euclidean((corner_left.x*image_w, corner_left.y*image_h), (corner_right.x*image_w, corner_right.y*image_h))
    normalized_mouth_width = mouth_width / face_width if face_width > 0 else 0

    # 웃음 점수 (입 너비와 입꼬리 상승 조합)
    smile_score = normalized_mouth_width * max(smile_lift, 0)

    # 눈썹 관련 (찌푸림/올라감)
    left_brow = face_landmarks.landmark[LEFT_INNER_BROW]
    right_brow = face_landmarks.landmark[RIGHT_INNER_BROW]
    brow_dist = euclidean((left_brow.x*image_w, left_brow.y*image_h), (right_brow.x*image_w, right_brow.y*image_h))
    avg_brow_y = (left_brow.y + right_brow.y) / 2.0
    avg_eye_y = (face_landmarks.landmark[33].y + face_landmarks.landmark[263].y) / 2.0
    brow_raise = (avg_eye_y - avg_brow_y)  # 양수면 눈썹이 올라간 것

    # 찌푸림 판단 (눈썹 좁아지고 아래로 내려온 상황)
    furrow = False
    if face_width > 0:
        norm_brow_dist = brow_dist / face_width
        if norm_brow_dist < 0.22 and avg_brow_y > avg_eye_y:
            furrow = True

    # 최종 피처 벡터
    vec = {
        "ear": ear if ear is not None else 0.0,
        "mouth_open": mouth_open,
        "smile_lift": smile_lift,
        "normalized_mouth_width": normalized_mouth_width,
        "smile_score": smile_score,
        "brow_raise": brow_raise,
        "furrow": 1.0 if furrow else 0.0
    }
    return vec

# ===============================
# 3. 감정 추론: 학습모델 + 룰 기반
# ===============================
def rule_based_emotion(feat):
    """
    학습모델이 없거나 실패할 때 사용하는 룰 기반 감정 추론
    """
    ear = feat["ear"]
    mouth_open = feat["mouth_open"]
    smile_score = feat["smile_score"]
    furrow = feat["furrow"]
    smile_lift = feat["smile_lift"]

    # 놀람 (눈 크게 뜨고 입도 벌어짐)
    if ear > 0.33 and mouth_open > 0.35:
        return "놀람"
    # 웃음: smile_score 기준
    if smile_score > 0.02:
        return "행복/웃음"
    # 화남: 찌푸림 + 입꼬리 내려감 + 입 다문 상태
    if furrow and smile_lift < -0.02 and mouth_open < 0.25:
        return "화남"
    # 슬픔: 입꼬리 내려가고 찌푸림은 아님, 입도 크게 벌어지지 않음
    if smile_lift < -0.02 and furrow == 0 and mouth_open < 0.25:
        return "슬픔"
    # 졸림/피로: 눈이 거의 감김
    if ear < 0.13:
        return "졸림/피로"
    # 그 외 중립
    return "중립"

def infer_emotion(face_landmarks, image_w, image_h):
    """
    face_landmarks로부터 feature vector를 만들고, 학습된 모델이 있으면 그것으로 예측.
    없으면 룰 기반 감정 추론 사용.
    """
    feat = feature_vector(face_landmarks, image_w, image_h)
    if classifier is not None:
        try:
            order = ["ear", "mouth_open", "smile_lift", "normalized_mouth_width", "smile_score", "brow_raise", "furrow"]
            x = np.array([feat[k] for k in order], dtype=float).reshape(1, -1)
            pred = classifier.predict(x)[0]
            return pred
        except Exception:
            pass  # 실패하면 룰 기반 fallback
    return rule_based_emotion(feat)

# ===============================
# 4. 웹 인터페이스: FastAPI 엔드포인트
# ===============================
@app.get("/", response_class=HTMLResponse)
def form(request: Request):
    """루트: 업로드 폼 렌더링"""
    return templates.TemplateResponse("index.html", {"request": request, "result": None})

@app.post("/predict", response_class=HTMLResponse)
async def predict(request: Request, file: UploadFile = File(...)):
    """
    업로드된 이미지 처리:
    - 얼굴 검출
    - 랜드마크 추출
    - 부위 시각화
    - 감정 추론
    - 결과 템플릿 반환
    """
    contents = await file.read()
    np_arr = np.frombuffer(contents, np.uint8)
    img = cv2.imdecode(np_arr, cv2.IMREAD_COLOR)
    if img is None:
        return templates.TemplateResponse("result.html", {
            "request": request,
            "error": "이미지를 읽을 수 없습니다.",
            "result": None
        })

    # MediaPipe는 RGB 입력
    rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    results = face_mesh.process(rgb)

    overlay = img.copy()
    h, w, _ = img.shape
    landmarks_info = {}

    predicted_emotion = "감지 안됨"
    if results.multi_face_landmarks:
        face_landmarks = results.multi_face_landmarks[0]

        # 부위 정보 추출
        left_eye = extract_region_info(face_landmarks, LEFT_EYE_IDX, w, h)
        right_eye = extract_region_info(face_landmarks, RIGHT_EYE_IDX, w, h)
        nose = extract_region_info(face_landmarks, NOSE_TIP_IDX, w, h)
        mouth = extract_region_info(face_landmarks, MOUTH_IDX, w, h)

        # 시각화: 바운딩박스/중심 등
        draw_region(overlay, left_eye, (0,255,255))
        draw_region(overlay, right_eye, (0,255,255))
        draw_region(overlay, nose, (255,0,0))
        draw_region(overlay, mouth, (255,0,255))

        # 전체 메쉬 시각화 (희미하게)
        mp_drawing.draw_landmarks(
            image=overlay,
            landmark_list=face_landmarks,
            connections=mp_face_mesh.FACEMESH_TESSELATION,
            landmark_drawing_spec=None,
            connection_drawing_spec=mp_drawing.DrawingSpec(color=(100,100,100), thickness=1, circle_radius=0)
        )

        # 감정 예측
        predicted_emotion = infer_emotion(face_landmarks, w, h)

        # 결과 정리
        landmarks_info = {
            "left_eye": left_eye,
            "right_eye": right_eye,
            "nose": nose,
            "mouth": mouth,
            "emotion": predicted_emotion
        }

    # 결과 이미지 저장
    out_name = f"{uuid.uuid4().hex}.png"
    out_path = os.path.join(OUTPUT_DIR, out_name)
    cv2.imwrite(out_path, overlay)

    result = {
        "image_path": f"/static/outputs/{out_name}",
        "landmarks": landmarks_info
    }

    # 템플릿 렌더링 (index에서 결과 보여주는 result.html)
    return templates.TemplateResponse("result.html", {
        "request": request,
        "result": result,
        "error": None
    })
```

labeled_expressions.csv
```
image_path,label
samples/angry1.jpg,화남
samples/angry2.jpg,화남
samples/smile1.jpg,행복/웃음
samples/smile2.jpg,행복/웃음
samples/sad1.jpg,슬픔
samples/normal1.jpg,무표정
samples/normal2.jpg,무표정
samples/normal3.jpg,무표정
```

templates/index.html
```html
<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>얼굴 랜드마크 & 표정 예측</title>
</head>
<body>
  <h1>얼굴 이미지 업로드 (표정 예측)</h1>
  <form action="/predict" method="post" enctype="multipart/form-data">
    <input type="file" name="file" accept="image/*" required />
    <button type="submit">예측</button>
  </form>
</body>
</html>
```

templates/result.html
```html
<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>예측 결과</title>
</head>
<body>
  <h1>얼굴 랜드마크 & 감정 결과</h1>
  {% if error %}
    <p style="color:red">{{ error }}</p>
  {% elif result %}
    <div>
      <h2>감정 추론</h2>
      <p><strong>예측된 감정:</strong> {{ result.landmarks.emotion }}</p>
    </div>
    <div>
      <h2>부위별 정보</h2>
      <ul>
        {% for part, info in result.landmarks.items() %}
          {% if info and part != "emotion" %}
            <li>
              <strong>{{ part.replace('_',' ').title() }}</strong><br/>
              중심점: (x: {{ info.centroid.x }}, y: {{ info.centroid.y }})<br/>
              바운딩박스: [{{ info.bbox.xmin }}, {{ info.bbox.ymin }}] - [{{ info.bbox.xmax }}, {{ info.bbox.ymax }}]<br/>
              점들:
              {% for p in info.points %}
                ({{ p.x }}, {{ p.y }}){% if not loop.last %}, {% endif %}
              {% endfor %}
            </li>
          {% endif %}
        {% endfor %}
      </ul>
    </div>
    <div>
      <h2>이미지</h2>
      <img src="{{ result.image_path }}" alt="annotated" style="max-width: 600px;" />
    </div>
  {% else %}
    <p>업로드된 이미지가 없습니다.</p>
  {% endif %}
  <p><a href="/">다시</a></p>
</body>
</html>
```

`1.` 역할 분리 (왜 두 개의 코드가 있는가?)
a. 학습용 스크립트 (`train_emotion.py`)
- 용도: 라벨이 붙은 얼굴 이미지들을 읽어서, 얼굴 특징(feature)을 뽑고, 그걸로 감정 분류기를 학습한다.
- 결과: `emotion_model.joblib` 같은 파일로 학습된 모델을 저장한다.
- 한 번 하고 끝 — 매번 실행할 필요 없이 저장된 모델을 재사용한다.
    
b. 추론/서비스 코드 (`main.py`, FastAPI)
- 용도: 사용자가 업로드한 이미지에서 얼굴 랜드마크를 뽑고, 그 얼굴 특징을 계산한 뒤, 저장된 학습된 모델로 감정을 예측한다.
- 실시간 처리: 웹에서 이미지가 들어올 때마다 빠르게 예측해서 결과를 보여준다.
- 학습은 여기서 하지 않는다. (느리고 비효율적이기 때문에)
    
---
`2.` 왜 학습을 요청이 들어올 때마다 하지 않나?
- 학습은 시간이 많이 걸린다. (즉, 이미지 하나 올릴 때마다 모델을 다시 만들면 너무 느려짐)
- 추론은 빠르게 해야 사용자 경험이 좋다.
- 그래서:  학습은 따로 하고 → 그 결과를 저장 → 추론에서는 저장된 모델만 불러다 쓴다.
    
---
`3.` 재학습이 필요하면 어떻게 하나?
- 새로운 라벨을 붙인 이미지가 생겼거나 더 정확하게 만들고 싶다면 모델을 다시 학습해야 한다.
- 그걸 위해 두 가지 방식이 있다:
    
`①` 수동 재학습(수동 학습이 훨씬 단순하고 제어하기 쉬움)
- `train_emotion.py`를 직접 실행해서 `emotion_model.joblib`을 새로 만든다.
```
python train_emotion.py
```
 
`②` FastAPI 안에 "재학습 시작" 기능 추가 (선택)
- `/retrain` 같은 API 경로를 만들어서 서버에서 백그라운드로 학습을 시작하게 할 수 있다.
- 예: 관리자 비밀키를 주고 호출하면 새로운 데이터로 모델을 다시 만들고 덮어쓴다.
- 즉시 응답은 주고, 내부에서 학습이 돌아가도록 한다.
    
> 주의: 이 경우도 실제 학습은 별도 함수로 분리하고, 요청마다 동기적으로 돌리면 서버가 멈출 수 있으니 `BackgroundTasks` 같은 방식으로 처리해야 한다.  
> 그리고 재학습 쓸 때는 인증(비밀키 등)을 꼭 넣어야 한다.

---
`4.` 전체 흐름 예시 (간단한 텍스트 다이어그램)
```
[라벨된 이미지들 + train_emotion.py]
            ↓ 학습
  [emotion_model.joblib 저장]
            ↓
[FastAPI(main.py)] ← 업로드된 이미지
            ↓
   [모델 로드 & 감정 예측]
            ↓
     [사용자에게 결과 표시]
```

필요하면 `/retrain`을 호출해서 다시 학습:
```
/retrain 요청 → 백그라운드로 train_emotion.py 로직 실행 → emotion_model.joblib 갱신
```

---
`5.` 정리
- 학습용 코드 (`train_emotion.py`): 모델을 만들고 저장.
- 서비스 코드 (`main.py`): 저장된 모델로 예측만 함.
- 재학습은 필요할 때만 하고, 즉 웹 요청 하나당 학습을 하면 안 됨.
- 좋은 확장: 학습/추론에 쓰는 피처 정의를 공통 모듈로 묶어두면 실수 줄어든다.

---
학습모델을 검색하여 사용하려고 할때 알아야 할 내용들...

`1.` `pickle(.pkl) vs joblib(.joblib):` 
- `pickle`은 파이썬 객체를 직렬화/역직렬화하는 일반적인 도구입니다. 어떤 객체든 저장할 수 있어서 텍스트 기반 모델(예: 사이킷런 파이프라인, 규칙 기반 객체 등)도 `.pkl`로 저장하는 데 무방합니다.
    
- `joblib`은 내부적으로 `pickle`을 쓰지만, 큰 NumPy 배열이나 과학 계산 모델 (특히 scikit-learn 모델처럼 내부에 배열이 많은 객체)에 대해서 더 빠르고 메모리/디스크 효율적인 직렬화를 제공합니다.  
    그래서 이미지 특징 벡터 기반으로 학습한 감정 분류기처럼 내부에 큰 수치 배열이 많은 경우 `joblib.dump`/`load`를 쓰는 게 일반적입니다.
    
###### `2.` 언제 무엇을 쓰면 좋을까요?
| 상황                                                              | 추천 저장 방식           | 이유                  |
| --------------------------------------------------------------- | ------------------ | ------------------- |
| 작은 파이썬 객체, 단순한 텍스트 모델/룰 기반 모델                                   | `pickle` (.pkl)    | 범용적이고 간단            |
| scikit-learn 모델 / 내부에 큰 NumPy 배열이 있는 모델 (예: 이미지 feature 기반 분류기) | `joblib` (.joblib) | 속도, 압축, 메모리 효율에서 유리 |

> 참고: `joblib`도 텍스트 모델(예: 어휘 사전, 로지스틱 회귀) 저장하는 데 사용할 수 있고, 반대로 `pickle`로도 scikit-learn 모델을 저장할 수 있습니다. 하지만 performance 측면에서 내부에 큰 배열이 많다면 `joblib`이 더 나은 선택입니다.

---
`1.` 이미 학습된 weight의 이점
- 학습 비용 절감: 처음부터 학습하지 않고 사전 학습된 가중치를 가져와서 미세조정(fine-tuning)만 하면 훨씬 빠릅니다.
- 성능 향상: 대규모 데이터로 미리 학습된 표현을 이용하면, 라벨이 적은 상황에서도 일반화 성능이 좋아질 수 있습니다.
- 빠른 배포: 이미 학습된 모델/weights를 바로 로드해서 추론 서버에 연결하면 “훈련 없이” 바로 서비스할 수 있습니다.
    
`2.` 저장 방식 구분
- 전통적/텍스트 기반 모델 (예: scikit-learn): 내부에 큰 수치 배열이 있어도 전체 객체를 `joblib` 또는 `pickle`로 직렬화해서 저장/불러옵니다.
- 딥러닝 모델:
    - `.pth`, `.pt` (PyTorch), `.ckpt`, `.h5` (TensorFlow/Keras) 등은 보통 가중치(state dict) 또는 체크포인트(구조+가중치)를 담고 있습니다.
    - 이들을 불러와서 아키텍처에 맞게 로드한 뒤 그대로 추론하거나, 일부 레이어만 재학습(fine-tuning)할 수 있습니다.
        
`3.` 주의할 점 / 반드시 확인할 것들
- 모델 구조 일치: weight만 가져다 쓸 때는 그 weight가 학습된 모델 구조(레이어 구성, 출력 클래스 수 등)와 정확히 맞아야 합니다. 구조가 다르면 로드 오류가 나거나 엉뚱한 동작을 합니다.
- 신뢰도/출처 검증: GitHub, HuggingFace 등에서 가져올 때
    - 누가 만든 건지, 학습에 어떤 데이터 썼는지, 설명과 코드가 공개돼 있는지
    - 라이선스가 무엇인지 (재배포/상용 사용 가능 여부)
    - 커밋/유지보수 상태 등을 확인해야 합니다.
- 버전 호환성: 예를 들어 PyTorch 버전이 다르면 `.pth`를 로드할 때 문제 생길 수 있고, scikit-learn의 경우도 버전 차이로 내부 속성이 달라질 수 있습니다.
- 보안: 직렬화된 파일(`.pkl`, `.joblib`, `.pth` 등)은 로딩 시 임의 코드 실행 위험이 있으므로, 신뢰할 수 없는 출처의 파일은 격리된 환경에서 먼저 테스트해야 합니다.
    
`4.` 실무 팁
- HuggingFace 또는 GitHub 같은 곳은 모델 카드와 함께 아키텍처/사용법/라이선스를 명시해두는 경우가 많아서, 처음 가져오기에는 비교적 안전하고 설명이 잘 되어 있습니다.
- 가능하면 “학습 코드도 함께 있는” 저장소를 가져와서 로컬에서 직접 재학습하거나 checkpoint를 재검증하는 것이 가장 안전합니다.