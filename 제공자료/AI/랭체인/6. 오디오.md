ì¢…ë¥˜ ì˜ˆì‹œ:
- íšŒì˜ë¡ íŒŒì´í”„ë¼ì¸: STTâ†’ìš”ì•½â†’ì•¡ì…˜ì•„ì´í…œ/ë‹´ë‹¹ì ì¶”ì¶œ
- ë³´ì´ìŠ¤ë´‡: ìŒì„± ì…ë ¥â†’ì´í•´â†’ë„êµ¬ ì‹¤í–‰â†’TTS ì‘ë‹µ
- ì½œì„¼í„° ë¶„ì„: í†µí™” í…ìŠ¤íŠ¸ ê°ì •/ì£¼ì œ ë¶„ë¥˜Â·í’ˆì§ˆ ì§€í‘œ ë¦¬í¬íŠ¸

---
##### ë³´ì´ìŠ¤ë´‡: 
ë¸Œë¼ìš°ì €ì—ì„œ ìŒì„±ì„ ë…¹ìŒ â†’ ì„œë²„ë¡œ ì—…ë¡œë“œ â†’ ê¸€ìë¡œ ë³€í™˜(STT) â†’ ì—ì´ì „íŠ¸ê°€ í•´ì„/íˆ´ ì‹¤í–‰ â†’ ë‹µë³€ì„ ìŒì„±ìœ¼ë¡œ ìƒì„±(TTS) â†’ ë¸Œë¼ìš°ì €ì—ì„œ ì¬ìƒ

- STT: í™ê¸¸ë™ íœ´ê°€ 2025-10-21ë¶€í„° 10-25ê¹Œì§€ ë“±ë¡í•´ì¤˜â€¦ (ì „ì‚¬ ê²°ê³¼)
- LLM: í™ê¸¸ë™ë‹˜ì˜ íœ´ê°€ë¥¼ ë“±ë¡í–ˆì–´ìš”. ID=ab12cd34 â€¦ (ìì—°ì–´ ë‹µë³€)
- ë„êµ¬ ì‹¤í–‰ ë¡œê·¸: ì–´ë–¤ íˆ´ì„ ì–´ë–¤ ì¸ìë¡œ í˜¸ì¶œí–ˆê³  ë¬´ì—‡ì„ ë°˜í™˜í–ˆëŠ”ì§€(JSON)
- ì˜¤ë””ì˜¤ í”Œë ˆì´ì–´: TTSë¡œ ìƒì„±ëœ MP3ê°€ ìë™ ì¬ìƒ 
- ìë™ ì¬ìƒë˜ëŠ” ê±´ LLMì˜ ìµœì¢… ë‹µë³€ì„ TTSë¡œ ë³€í™˜í•œ MP3 ì…ë‹ˆë‹¤.

`0)`ìƒˆ í”„ë¡œì íŠ¸ & ì„¤ì¹˜
```bash
mkdir voicebot-agent && cd voicebot-agent
python -m venv .venv && source .venv/bin/activate  # (Windows: .venv\Scripts\activate)

pip install langchain==0.1.10 langchain-openai openai fastapi uvicorn python-dotenv pydantic python-multipart
```

`.env`
```env
OPENAI_API_KEY=sk-...             # í•„ìˆ˜
OPENAI_MODEL=gpt-3.5-turbo-0125   # LLM (íˆ´ì½œìš©)
TTS_MODEL=gpt-4o-mini-tts         # í…ìŠ¤íŠ¸â†’ìŒì„±
STT_MODEL=whisper-1               # ìŒì„±â†’í…ìŠ¤íŠ¸
VOICE=alloy                       # TTS ëª©ì†Œë¦¬
```

`1)` ë””ë ‰í† ë¦¬ êµ¬ì¡°
```bash
voicebot-agent/
â”œâ”€ app/
â”‚  â”œâ”€ main.py
â”‚  â”œâ”€ api/
â”‚  â”‚   â””â”€ voice_routes.py
â”‚  â””â”€ agent/
â”‚      â”œâ”€ agent.py     # LLM + íˆ´ì½œ ë¡œì§
â”‚      â””â”€ tools.py     # ì—…ë¬´ ìë™í™” íˆ´ (ì˜ˆ: íœ´ê°€/ì´ìŠˆ)
â”œâ”€ uploads/            # ì—…ë¡œë“œ/ìƒì„± ìŒì„± íŒŒì¼ ì €ì¥ (ìë™ ìƒì„±)
â”œâ”€ web/
â”‚  â””â”€ index.html       # ë¸Œë¼ìš°ì € UI (ë…¹ìŒ/ì „ì†¡/ì¬ìƒ)
â””â”€ .env
```
ì•ˆì „í•œ ì„í¬íŠ¸ë¥¼ ìœ„í•´ `app/`, `app/api/`, `app/agent/`ì— **ë¹ˆ `__init__.py`** í•˜ë‚˜ì”© ë§Œë“¤ì–´ë‘ë©´ ì¢‹ì•„ìš”.

`2)` íˆ´ ì •ì˜ â€” `app/agent/tools.py`
LLMì´ ì‹¤ì œ ì‘ì—…ì„ ë„êµ¬ë¡œ ì‹¤í–‰. ì—¬ê¸°ì„  íœ´ê°€ ë“±ë¡Â·ì´ìŠˆ ìƒì„±ì„ JSON íŒŒì¼ì— ì €ì¥í•˜ëŠ” ëª¨ì˜ APIë¡œ êµ¬í˜„(ì‹¤ì„œë¹„ìŠ¤ëŠ” Jira/Calendarë¡œ êµì²´)
```python
# app/agent/tools.py
import os, json, uuid, datetime
from typing import Optional, Literal
from langchain_core.tools import tool
from langchain_core.pydantic_v1 import BaseModel, Field

DATA_DIR = os.path.join(os.path.dirname(os.path.dirname(__file__)), "..", "uploads")
os.makedirs(DATA_DIR, exist_ok=True)
CAL_PATH = os.path.abspath(os.path.join(DATA_DIR, "calendar.json"))
ISS_PATH = os.path.abspath(os.path.join(DATA_DIR, "issues.json"))

def _load(path: str):
    if not os.path.exists(path):
        with open(path, "w", encoding="utf-8") as f:
            json.dump([], f, ensure_ascii=False)
    with open(path, "r", encoding="utf-8") as f:
        return json.load(f)

def _save(path: str, data):
    with open(path, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

# ----- íœ´ê°€ ë“±ë¡ -----
class VacationInput(BaseModel):
    employee: str = Field(..., description="ì§ì› ì´ë¦„")
    start_date: str = Field(..., description="YYYY-MM-DD")
    end_date: str = Field(..., description="YYYY-MM-DD")
    reason: Optional[str] = None

@tool("create_vacation", args_schema=VacationInput)
def create_vacation(employee: str, start_date: str, end_date: str, reason: Optional[str] = None) -> dict:
    """íœ´ê°€ ì¼ì • ë“±ë¡."""
    try:
        sd = datetime.date.fromisoformat(start_date)
        ed = datetime.date.fromisoformat(end_date)
        assert ed >= sd
    except Exception:
        return {"ok": False, "error": "ë‚ ì§œ í˜•ì‹/ìˆœì„œ ì˜¤ë¥˜(YYYY-MM-DD, ì¢…ë£Œ>=ì‹œì‘)"}
    data = _load(CAL_PATH)
    item = {
        "id": uuid.uuid4().hex[:8],
        "employee": employee,
        "start_date": start_date,
        "end_date": end_date,
        "reason": reason or "",
        "created_at": datetime.datetime.utcnow().isoformat() + "Z",
    }
    data.append(item); _save(CAL_PATH, data)
    return {"ok": True, "vacation": item}

# ----- ì´ìŠˆ ìƒì„± -----
class IssueInput(BaseModel):
    title: str
    description: str
    priority: Literal["low","medium","high"] = "medium"
    assignee: Optional[str] = None

@tool("create_issue", args_schema=IssueInput)
def create_issue(title: str, description: str, priority: str = "medium", assignee: Optional[str] = None) -> dict:
    """ì´ìŠˆ ìƒì„±."""
    data = _load(ISS_PATH)
    item = {
        "id": uuid.uuid4().hex[:8],
        "title": title,
        "description": description,
        "priority": priority,
        "assignee": assignee or "",
        "status": "open",
        "created_at": datetime.datetime.utcnow().isoformat() + "Z",
    }
    data.append(item); _save(ISS_PATH, data)
    return {"ok": True, "issue": item}
```

`3)` ì—ì´ì „íŠ¸(íˆ´ ì½œë§) â€” `app/agent/agent.py`
**íë¦„**: (1) í…ìŠ¤íŠ¸ ëª…ë ¹ â†’ (2) íˆ´ í•„ìš”Â·íŒŒë¼ë¯¸í„° ìë™ê²°ì • â†’ (3) íˆ´ ì‹¤í–‰ â†’ (4) ê²°ê³¼ ë°˜ì˜í•´ ìµœì¢… ë‹µë³€
```python
# app/agent/agent.py
import os
from typing import Dict, Any, List
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, HumanMessage, ToolMessage, AIMessage
from .tools import create_vacation, create_issue

load_dotenv()
MODEL = os.getenv("OPENAI_MODEL", "gpt-3.5-turbo-0125")

# LLM + íˆ´ ë°”ì¸ë”©
_llm = ChatOpenAI(model=MODEL, temperature=0)
_llm_tools = _llm.bind_tools([create_vacation, create_issue])
_TOOL_REGISTRY = {"create_vacation": create_vacation, "create_issue": create_issue}

SYS_PROMPT = (
    "You are a Korean office voice assistant. "
    "Use tools to execute tasks (vacation, issue). "
    "Dates must be YYYY-MM-DD. If date is vague, ask for clarification in Korean."
)

def run_agent(user_text: str) -> Dict[str, Any]:
    messages: List = [SystemMessage(content=SYS_PROMPT), HumanMessage(content=user_text)]
    # (1) íˆ´ ì„ íƒ/ì¸ì ì¶”ë¡ 
    ai_msg: AIMessage = _llm_tools.invoke(messages)

    tool_calls = getattr(ai_msg, "tool_calls", None)
    if not tool_calls:
        final = _llm.invoke(messages + [ai_msg])
        return {"reply": final.content, "tool_calls": [], "tool_results": []}

    # (2) íˆ´ ì‹¤í–‰
    tool_results, tool_msgs = [], []
    for call in tool_calls:
        name, args = call["name"], call.get("args", {})
        tool = _TOOL_REGISTRY.get(name)
        if tool:
            result = tool.invoke(args)
        else:
            result = {"ok": False, "error": "unknown tool"}
        tool_results.append({"tool": name, "args": args, "result": result})
        tool_msgs.append(ToolMessage(tool_call_id=call["id"], content=str(result)))

    # (3) ê²°ê³¼ ë°˜ì˜í•´ ìµœì¢… ë‹µë³€
    final = _llm.invoke(messages + [ai_msg] + tool_msgs)
    return {"reply": final.content, "tool_calls": tool_calls, "tool_results": tool_results}
```

`4)` ìŒì„± ì²˜ë¦¬ API â€” `app/api/voice_routes.py`
í•œ ë²ˆì˜ ìš”ì²­ìœ¼ë¡œ STTâ†’ì—ì´ì „íŠ¸â†’TTSê¹Œì§€ ì‹¤í–‰.  
ìš”ì²­: `multipart/form-data`(audio íŒŒì¼) + (ì„ íƒ) `hint` í…ìŠ¤íŠ¸
```python
# app/api/voice_routes.py
import os, uuid
from fastapi import APIRouter, UploadFile, File, Form, HTTPException
from fastapi.responses import JSONResponse
from dotenv import load_dotenv
from openai import OpenAI
from app.agent.agent import run_agent

load_dotenv()
router = APIRouter(prefix="/voice", tags=["voice"])

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
STT_MODEL = os.getenv("STT_MODEL", "whisper-1")
TTS_MODEL = os.getenv("TTS_MODEL", "gpt-4o-mini-tts")
VOICE = os.getenv("VOICE", "alloy")
UPLOAD_DIR = os.getenv("UPLOAD_DIR", "uploads")
os.makedirs(UPLOAD_DIR, exist_ok=True)

client = OpenAI(api_key=OPENAI_API_KEY)

@router.get("/ping")
def ping():
    return {"ok": True}

@router.post("/handle")
async def handle_voice(audio: UploadFile = File(...), hint: str = Form(None)):
    # 1) ê²€ì¦
    if not audio.content_type or not audio.content_type.startswith("audio/"):
        # ë¸Œë¼ìš°ì € MediaRecorderëŠ” 'audio/webm' ë“±ìœ¼ë¡œ ì „ì†¡ë©ë‹ˆë‹¤.
        raise HTTPException(400, "ì˜¤ë””ì˜¤ íŒŒì¼ë§Œ ì—…ë¡œë“œí•˜ì„¸ìš”.")

    # 2) ì €ì¥(ì„ íƒ: ì—…ë¡œë“œ ì›ë³¸ ë³´ê´€)
    ext = os.path.splitext(audio.filename or "")[1] or ".webm"
    in_name = f"{uuid.uuid4().hex}{ext}"
    in_path = os.path.join(UPLOAD_DIR, in_name)
    raw = await audio.read()
    with open(in_path, "wb") as f:
        f.write(raw)

    # 3) STT(Whisper)
    try:
        with open(in_path, "rb") as f:
            tr = client.audio.transcriptions.create(model=STT_MODEL, file=f, prompt=hint or None)
        text = tr.text or ""
    except Exception as e:
        raise HTTPException(500, f"STT ì‹¤íŒ¨: {e}")

    if not text.strip():
        return JSONResponse({"transcript": "", "reply": "ìŒì„±ì„ ì¸ì‹í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.", "audio_url": None})

    # 4) ì—ì´ì „íŠ¸(íˆ´ì½œ)
    try:
        agent_out = run_agent(text)
        reply_text = agent_out.get("reply") or "ì²˜ë¦¬ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤."
    except Exception as e:
        raise HTTPException(500, f"ì—ì´ì „íŠ¸ ì˜¤ë¥˜: {e}")

    # 5) TTS
    out_name = f"tts_{uuid.uuid4().hex}.mp3"
    out_path = os.path.join(UPLOAD_DIR, out_name)
    try:
        speech = client.audio.speech.create(model=TTS_MODEL, voice=VOICE, input=reply_text)
        with open(out_path, "wb") as f:
            f.write(speech.content)
    except Exception as e:
        # TTS ì‹¤íŒ¨í•´ë„ í…ìŠ¤íŠ¸ëŠ” ëŒë ¤ì£¼ì
        return JSONResponse({"transcript": text, "reply": reply_text, "audio_url": None, "tool": agent_out})

    return JSONResponse({
        "transcript": text,
        "reply": reply_text,
        "audio_url": f"/uploads/{out_name}",
        "tool": agent_out  # ë””ë²„ê¹…ìš©(íˆ´ì½œ/ê²°ê³¼)
    })
```

`5)` FastAPI ì•± â€” `app/main.py`
ì •ì  í”„ë¡ íŠ¸(`/web`) & ì—…ë¡œë“œ(`/uploads`) ì„œë¹™ + ë¼ìš°í„° í¬í•¨
```python
# app/main.py
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
from fastapi.responses import RedirectResponse
from app.api.voice_routes import router as voice_router

app = FastAPI(title="Voice Assistant (Tool-Calling)", version="1.0.0")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"], allow_credentials=True,
    allow_methods=["*"], allow_headers=["*"],
)

app.include_router(voice_router)

# ì •ì /ì—…ë¡œë“œ ì„œë¹™
app.mount("/web", StaticFiles(directory="web", html=True), name="web")
app.mount("/uploads", StaticFiles(directory="uploads"), name="uploads")

@app.get("/")
def root():
    return RedirectResponse(url="/web/")
```

`6)` í”„ë¡ íŠ¸ â€” `web/index.html`
ë…¹ìŒ â†’ ì—…ë¡œë“œ â†’ ì‘ë‹µ í…ìŠ¤íŠ¸ + ìŒì„± ì¬ìƒ. MediaRecorder API ì‚¬ìš©.
```html
<!doctype html>
<html lang="ko">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width,initial-scale=1"/>
  <title>ë³´ì´ìŠ¤ë´‡ (íˆ´ ì½œë§)</title>
  <script src="https://cdn.tailwindcss.com"></script>
</head>
<body class="bg-slate-50 text-slate-900">
  <div class="max-w-3xl mx-auto p-6">
    <h1 class="text-2xl font-bold mb-2">ë³´ì´ìŠ¤ë´‡: ìŒì„±â†’ì´í•´â†’íˆ´ ì‹¤í–‰â†’TTS ì‘ë‹µ</h1>
    <p class="text-sm text-slate-600 mb-6">â€œí™ê¸¸ë™ íœ´ê°€ 2025-10-21~2025-10-25 ë“±ë¡í•´ì¤˜â€ ê°™ì´ ë§í•´ë³´ì„¸ìš”.</p>

    <section class="bg-white rounded-2xl shadow p-5 space-y-3">
      <div class="flex gap-2 items-center">
        <button id="recBtn" class="px-4 py-2 rounded-xl bg-blue-600 text-white hover:bg-blue-700">
          ğŸ™ï¸ ë…¹ìŒ ì‹œì‘
        </button>
        <span id="state" class="text-sm text-slate-600">ëŒ€ê¸° ì¤‘</span>
      </div>
      <div>
        <label class="text-sm font-medium">íŒíŠ¸(ì„ íƒ): </label>
        <input id="hint" class="border rounded-lg px-3 py-1 w-full" placeholder="ë„ë©”ì¸ íŒíŠ¸(ì˜ˆ: ë‚ ì§œëŠ” YYYY-MM-DDë¡œ ë§í•´ì£¼ì„¸ìš”)"/>
      </div>
      <audio id="play" controls class="w-full hidden"></audio>
    </section>

    <section class="bg-white rounded-2xl shadow p-5 mt-5 hidden" id="result">
      <h2 class="text-lg font-semibold mb-2">ê²°ê³¼</h2>
      <div class="text-sm"><span class="font-semibold">STT:</span> <span id="stt"></span></div>
      <div class="text-sm mt-1"><span class="font-semibold">LLM:</span> <span id="llm"></span></div>
      <details class="mt-3">
        <summary class="cursor-pointer text-sm text-slate-600">ë„êµ¬ ì‹¤í–‰ ë¡œê·¸</summary>
        <pre id="tool" class="bg-slate-100 rounded-lg p-3 text-xs overflow-auto"></pre>
      </details>
    </section>
  </div>

  <script>
    const recBtn = document.getElementById('recBtn');
    const state = document.getElementById('state');
    const hint = document.getElementById('hint');
    const audioEl = document.getElementById('play');
    const resultSec = document.getElementById('result');
    const sttEl = document.getElementById('stt');
    const llmEl = document.getElementById('llm');
    const toolEl = document.getElementById('tool');

    let media, recorder, chunks = [], recording = false;

    recBtn.addEventListener('click', async () => {
      if (!recording) {
        try {
          media = await navigator.mediaDevices.getUserMedia({ audio: true });
          const mime = MediaRecorder.isTypeSupported('audio/webm') ? 'audio/webm' : undefined;
          recorder = new MediaRecorder(media, mime ? { mimeType: mime } : undefined);
          chunks = [];
          recorder.ondataavailable = e => { if (e.data.size) chunks.push(e.data); };
          recorder.onstop = onStop;
          recorder.start();
          recording = true;
          recBtn.textContent = 'â¹ï¸ ë…¹ìŒ ì¢…ë£Œ';
          state.textContent = 'ë…¹ìŒ ì¤‘â€¦';
        } catch (e) {
          alert('ë§ˆì´í¬ ì ‘ê·¼ ì‹¤íŒ¨: ' + e);
        }
      } else {
        recorder?.stop();
        media?.getTracks()?.forEach(t => t.stop());
        recording = false;
        recBtn.textContent = 'ğŸ™ï¸ ë…¹ìŒ ì‹œì‘';
        state.textContent = 'ì²˜ë¦¬ ì¤‘â€¦';
      }
    });

    async function onStop() {
      const blob = new Blob(chunks, { type: 'audio/webm' });
      // ë¯¸ë¦¬ ë“¤ì„ ìˆ˜ë„ ìˆìŒ
      audioEl.src = URL.createObjectURL(blob);
      audioEl.classList.remove('hidden');

      const fd = new FormData();
      fd.append('audio', blob, `record_${Date.now()}.webm`);
      if (hint.value.trim()) fd.append('hint', hint.value.trim());

      try {
        const res = await fetch('/voice/handle', { method: 'POST', body: fd });
        if (!res.ok) throw new Error('ì„œë²„ ì˜¤ë¥˜: ' + (await res.text()));
        const data = await res.json();
        // ê²°ê³¼ í‘œì‹œ
        resultSec.classList.remove('hidden');
        sttEl.textContent = data?.transcript || '';
        llmEl.textContent = data?.reply || '';
        toolEl.textContent = JSON.stringify(data?.tool || {}, null, 2);

        if (data?.audio_url) {
          audioEl.src = data.audio_url;   // TTSë¡œ êµì²´
          audioEl.play().catch(()=>{});
        }
        state.textContent = 'ì™„ë£Œ';
      } catch (e) {
        state.textContent = 'ì‹¤íŒ¨';
        alert('ìš”ì²­ ì‹¤íŒ¨: ' + e.message);
      }
    }
  </script>
</body>
</html>
```

`7)` ì‹¤í–‰ & í…ŒìŠ¤íŠ¸
```bash
uvicorn app.main:app --reload --port 8000
```
ë¸Œë¼ìš°ì €ì—ì„œ `http://localhost:8000/` ì ‘ì† â†’ ë…¹ìŒ ì‹œì‘ ëˆŒëŸ¬ ë§í•˜ê¸° â†’ 
ë…¹ìŒ ì¢…ë£Œ â†’  STT í…ìŠ¤íŠ¸/LLM ë‹µë³€ í™•ì¸ + TTS ìŒì„± ìë™ ì¬ìƒ.